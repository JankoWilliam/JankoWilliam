<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JankoWilliam's blog]]></title>
    <url>%2F2018%2F12%2F29%2Findex%2F</url>
    <content type="text"><![CDATA[12寄语： 年少如你，不曾奢望今夕，就像我们不曾奢望今生能够与你相遇，人生中一切的遇见或许都是命中注定。命中注定你心属耶稣，命中注定你信仰上帝。时光可以改变你阳光的面庞，却无法改变你虔诚的信仰，因为永远仰望天空，因为笃定的深情，我们才有幸与最好的你在2007年相遇。那也是你最好的样子那也是你永远的样子。我们爱你那时的样子，也爱那时的我们爱你的样子。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hexo整合GitHub个人博客]]></title>
    <url>%2F2016%2F06%2F25%2Fmd_%E5%85%B6%E5%AE%83%2FHexo%E6%95%B4%E5%90%88GitHub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[更新博客：hexo根目录下 Git Bush Here 123$ hexo clean$ hexo generate$ hexo deploy 为博客添加标签项： hexo根目录下 Git Bush Here 创建tags文件夹 1$ hexo new page tags 到安装盘:\hexo\source\tags文件夹下，修改index.md： 1234title: 标签date: 日期type: "tags"comments: false 为博客添加标签，在md文件头添加： 123title: xxxxx标题tags: - 标签1 为博客添加分类项：hexo根目录下 Git Bush Here 创建categories文件夹 1$ hexo new page categories 到安装盘:\hexo\source\categories文件夹下，修改index.md： 1234title: 分类date: 日期type: "categories"comments: false 为博客添加标签，在md文件头添加： 123title: xxxxx标题categories: - 类别1 更换博客主题： 浏览Hexo主题网站，选取主题复制github上的HTTPS地址，如：https://github.com/wizardforcel/hexo-theme-cyanstyle.git； hexo根目录下 Git Bush Here： 1$ git clone https://github.com/wizardforcel/hexo-theme-cyanstyle.git themes/cyanstyle 下载主题到hexo/themes/cyanstyle文件夹下； 记事本打开hexo根目录下_config.yml文件，修改： 1theme: cyanstyle 默认主题为 theme：landscape； 更新博客既更换了主题。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据009——MapReduce]]></title>
    <url>%2F2016%2F04%2F03%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE009%E2%80%94%E2%80%94MapReduce%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据008——Yarn]]></title>
    <url>%2F2016%2F04%2F02%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE008%E2%80%94%E2%80%94Yarn%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据007——HDFS2.0]]></title>
    <url>%2F2016%2F04%2F01%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE007%E2%80%94%E2%80%94HDFS2.0%2F</url>
    <content type="text"><![CDATA[1. Hadoop 2.01.1 Hadoop1.0于Hadoop2.0的区别1）. 从整体框架来说 ​ a. Hadoop1.0即第一代Hadoop，由分布式存储系统HDFS和分布式计算框架MapReduce组成，其中HDFS由一个NameNode和多个DateNode组成，MapReduce由一个JobTracker和多个TaskTracker组成。 ​ b. Hadoop2.0即第二代Hadoop，内核主要由HDFS、MapReduce和YARN三个系统组成，其中YARN是一个资源管理系统，负责集群资源管理和调度，MapReduce则是运行在YARN上的离线处理框架，它与Hadoop 1.0中的MapReduce在编程模型（新旧API）和数据处理引擎（MapTask和ReduceTask）两个方面是相同的。针对Hadoop1.0单NameNode制约HDFS的扩展性问题，提出HDFS Federation（联盟），它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时彻底解决了NameNode单点故障问题 2）. 从MapReduce计算框架来说 ​ a. MapReduce1.0计算框架主要由三部分组成：编程模型、数据处理引擎和运行时环境。它的基本编程模型是将问题抽象成Map和Reduce两个阶段，其中Map阶段将输入的数据解析成key/value，迭代调用map()函数处理后，再以key/value的形式输出到本地目录，Reduce阶段将key相同的value进行规约处理，并将最终结果写到HDFS上；它的数据处理引擎由MapTask和ReduceTask组成，分别负责Map阶段逻辑和Reduce阶段的逻辑处理；它的运行时环境由一个JobTracker和若干个TaskTracker两类服务组成，其中JobTracker负责资源管理和所有作业的控制，TaskTracker负责接收来自JobTracker的命令并执行它。​ b. MapReducer2.0具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1基础上经加工之后，运行于资源管理框架Yarn之上的计算框架MapReduce。它的运行时环境不再由JobTracker和TaskTracker等服务组成，而是变为通用资源管理系统Yarn和作业控制进程ApplicationMaster，其中Yarn负责资源管理的调度而ApplicationMaster负责作业的管理。 2. HDFS 2.0 HA高可用2.1 HDFS HA背景​ 在Hadoop 1.x 中，Namenode是集群的单点故障，一旦Namenode出现故障，整个集群将不可用，重启或者开启一个新的Namenode才能够从中恢复。值得一提的是，Secondary Namenode并没有提供故障转移的能力。集群的可用性受到影响表现在： 当机器发生故障，如断电时，管理员必须重启Namenode才能恢复可用。 在日常的维护升级中，需要停止Namenode，也会导致集群一段时间不可用 1.2 HDFS HA架构​ Hadoop HA（High Available）通过同时配置两个处于Active/Passive模式的Namenode来解决上述问题，分别叫Active Namenode和Standby Namenode. Standby Namenode作为热备份，从而允许在机器发生故障时能够快速进行故障转移，同时在日常维护的时候使用优雅的方式进行Namenode切换。Namenode只能配置一主一备，不能多于两个Namenode。两个Namenode存在以下特点： 主Namenode处理所有的操作请求（读写），而Standby只是作为slave； 两个Namenode都与一组Journal Node进行通信； 当进行故障转移时，Standby在成为Active Namenode之前，会确保自己已经读取了Journal Node中的所有edit日志，从而保持数据状态与故障发生前一致； Datanode同时配置主备两个Namenode，并同时发送Block报告和心跳到两台Namenode； 为了防止这种脑裂现象（两台Namenode都认为自己的Active Namenode时），Journal Nodes只允许一个Namenode写入数据，内部通过维护epoch数来控制，从而安全地进行故障转移； 有两种方式可以进行edit log共享： 使用NFS共享edit log（存储在NAS/SAN）； 使用QJM共享edit log。 1.3 Federation联邦​ 通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使到namenode/namespace可以通过增加机器来进行水平扩展。 ​ 能把单个namenode的负载分散到多个节点中，在HDFS数据规模较大的时候不会也降低HDFS的性能。可以通过多个namespace来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中。 1.4 使用Zookeeper进行自动故障转移​ 前面提到，为了支持故障转移，Hadoop引入两个新的组件：Zookeeper Quorum和ZKFailoverController process（简称ZKFC）。 ​ Zookeeper的任务包括： 失败检测： 每个Namnode都在ZK中维护一个持久性session，如果Namnode故障，session过期，使用zk的事件机制通知其他Namenode需要故障转移； Namenode选举：如果当前Active namenode挂了，另一个namenode会尝试获取ZK中的一个排它锁，获取这个锁就表名它将成为下一个Active NN。 在每个Namenode守护进程的机器上，同时也会运行一个ZKFC，用于完成以下任务： Namenode健康 ZK Session管理 基于ZK的Namenode选举 ​ 如果ZKFC所在机器的Namenode健康状态良好，并且用于选举的znode锁未被其他节点持有，则ZKFC会尝试获取锁,成功获取这个排它锁就代表获得选举，获得选举之后负责故障转移，如果有必要，会fencing掉之前的namenode使其不可用，然后将自己的namenode切换为Active状态。 3. Hadoop2.X HA搭建]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据006——Zookeeper]]></title>
    <url>%2F2016%2F03%2F30%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE006%E2%80%94%E2%80%94Zookeeper%2F</url>
    <content type="text"><![CDATA[1. 前言1.1 Zookeeper简介ZooKeeper是一个分布式的，开源的分布式应用程序协调服务**，是[Google](http://baike.baidu.com/item/Google)的Chubby一个[开源](http://baike.baidu.com/item/%E5%BC%80%E6%BA%90)的实现，**是Hadoop和Hbase的重要组件。 ​ 目前，大部分应用需要开发私有的一个主控、协调器或控制器的协调程序来管理物理分布的子进程（如资源、任务分配等）。而协调程序的反复编写浪费，且难以形成通用、伸缩性好的协调器,所以zookeeper应用而生。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 1.2 ZooKeeper典型应用场景一览 1. 数据发布与订阅（配置中心） 发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。应用场景如下：a. 应用中用到的一些配置信息放到ZK上进行集中管理；b. 分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在ZK的一些指定节点，供各个客户端订阅使用；c. 分布式日志收集系统；d. 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息的发问。 2. 负载均衡 这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。 3. 命名服务(Naming Service) 命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 4. 分布式通知/协调 ZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理。 5. 集群管理与Master选举 群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。 6. 分布式锁 分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 7. 分布式队列 队列方面，简单地讲有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。 1.3 Zookeeper的角色2. Zookeeper安装部署注：windows下zookeeper集群搭建请参考:Zookeeper 在Windows下的安装过程及测试。 3. Zookeeper基础命令3.1 配置Zookeeper环境变量，方便指令操作1[root@node01 ~]# vim ~/.bash_profile 在后面添加： 12export ZOOKEEPER_HOME=/usr/zookeeper-3.4.6 #这里修改为zookeeper根目录PATH=$PATH:$ZOOKEEPER_HOME/bin 然后重新加载环境变量： 1[root@node01 ~]# source ~/.bash_profile 查看zookeeper环境变量是否配置成功，任意目录下输入z，按Tab键： 123[root@node01 ~]# zzcat zdiff zegrep zforce zic zkCli.cmd zkEnv.cmd zkServer.cmd zless znew zcmp zdump zfgrep zgrep zkCleanup.sh zkCli.sh zkEnv.sh zkServer.sh zmore zsoelim 会提示出zookeeper的所有指令。 3.2 基础命令操作 启动zk服务： 1[root@node01 ~]# zkServer.sh start 1234[root@node01 ~]# zkServer.sh startJMX enabled by defaultUsing config: /usr/zookeeper-3.4.6/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 查看zk运行状态： 1[root@node01 ~]# zkServer.sh status 1234[root@node01 ~]# zkServer.sh statusJMX enabled by defaultUsing config: /usr/zookeeper-3.4.6/bin/../conf/zoo.cfgMode: follower #这里显示的状态为跟随者，用于接收客户端请求并向客户端返回结果，在选主过程中参与投票 停止zk服务： 1[root@node01 ~]# zkServer.sh stop 客户端连接zk: 123456[root@node01 ~]# zkCli.sh......WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: localhost:2181(CONNECTED) 0] help 查看客户端帮助命令： 1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 0] help ZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port ls：查看目录命令（mynode和hadoop-ha是我测试集群创建的节点，默认只有一个zookeeper节点） 123456[zk: localhost:2181(CONNECTED) 0] ls /[mynode, zookeeper, hadoop-ha][zk: localhost:2181(CONNECTED) 1] ls /zookeeper[quota][zk: localhost:2181(CONNECTED) 2] ls /zookeeper/quota[] get： 获取节点数据和更新信息 12345678910111213[zk: localhost:2181(CONNECTED) 3] get /zookeeper #下面空行说明节点内容为空cZxid = 0x0 #创建节点的idctime = Thu Jan 01 08:00:00 CST 1970 #节点的创建时间mZxid = 0x0 #修改节点的idmtime = Thu Jan 01 08:00:00 CST 1970 #修改节点的时间pZxid = 0x0 #子节点的idcversion = -1 #子节点的版本dataVersion = 0 #当前节点数据的版本aclVersion = 0 #权限的版本ephemeralOwner = 0x0 #判断是否是临时节点dataLength = 0 #数据的长度numChildren = 1 #子节点的数量 stat ：获得节点的更新信息 12345678910111213[zk: localhost:2181(CONNECTED) 3] get /zookeeper #下面空行说明节点内容为空cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 stat：获得节点的更新信息 123456789101112[zk: localhost:2181(CONNECTED) 0] stat /zookeepercZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 ls2：ls命令和stat命令的整合 12345678910111213[zk: localhost:2181(CONNECTED) 1] ls2 /zookeeper[quota]cZxid = 0x0ctime = Thu Jan 01 08:00:00 CST 1970mZxid = 0x0mtime = Thu Jan 01 08:00:00 CST 1970pZxid = 0x0cversion = -1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 1 create：创建节点 1create [-s] [-e] path data acl #语法格式 123456789101112131415[zk: localhost:2181(CONNECTED) 13] create /testnode HelloZookeeper Created /testnode[zk: localhost:2181(CONNECTED) 14] get /testnodeHelloZookeepercZxid = 0x200000012ctime = Fri Jan 04 18:55:06 CST 2019mZxid = 0x200000012mtime = Fri Jan 04 18:55:06 CST 2019pZxid = 0x200000012cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 14numChildren = 0 create -e：创建临时节点 123456789101112131415161718#创建临时节点[zk: localhost:2181(CONNECTED) 0] delete /testnode/temp[zk: localhost:2181(CONNECTED) 1] create -e /testnode/temp tempdataCreated /testnode/temp#断开连接[zk: localhost:2181(CONNECTED) 2] quitQuitting...2019-01-04 19:00:59,261 [myid:] - INFO [main-EventThread:ClientCnxn$EventThread@512] - EventThread shut down2019-01-04 19:00:59,261 [myid:] - INFO [main:ZooKeeper@684] - Session: 0x1681843584f0007 closed[root@node01 ~]# zkCli.shConnecting to localhost:2181......WATCHER::WatchedEvent state:SyncConnected type:None path:null#断开重连之后，临时节点自动消失[zk: localhost:2181(CONNECTED) 0] ls /testnode [] create -s：创建顺序节点 自动累加 12345# 创建顺序节点，顺序节点会自动累加[zk: localhost:2181(CONNECTED) 1] create -s /testnode/sec secdataCreated /testnode/sec0000000001[zk: localhost:2181(CONNECTED) 2] create -s /testnode/sec secdataCreated /testnode/sec0000000002 set：修改节点 1set path data [version] #语法格式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[zk: localhost:2181(CONNECTED) 9] get /mynode123456aaaaaacZxid = 0x200000002ctime = Fri Jan 04 17:54:16 CST 2019mZxid = 0x200000002mtime = Fri Jan 04 17:54:16 CST 2019pZxid = 0x20000001fcversion = 6dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 12numChildren = 0# 修改节点内容为 newdata[zk: localhost:2181(CONNECTED) 10] set /mynode newdatacZxid = 0x200000002ctime = Fri Jan 04 17:54:16 CST 2019mZxid = 0x200000020mtime = Fri Jan 04 19:09:13 CST 2019pZxid = 0x20000001fcversion = 6dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0#再次查询，节点内容已经修改[zk: localhost:2181(CONNECTED) 11] get /mynodenewdatacZxid = 0x200000002ctime = Fri Jan 04 17:54:16 CST 2019mZxid = 0x200000020mtime = Fri Jan 04 19:09:13 CST 2019pZxid = 0x20000001fcversion = 6dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0#set 根据版本号更新 dataVersion 乐观锁（注意请从1开始设置）[zk: localhost:2181(CONNECTED) 15] set /mynode newdata02 1cZxid = 0x200000002ctime = Fri Jan 04 17:54:16 CST 2019mZxid = 0x200000024mtime = Fri Jan 04 19:12:27 CST 2019pZxid = 0x20000001fcversion = 6dataVersion = 2aclVersion = 0ephemeralOwner = 0x0dataLength = 9numChildren = 0#因为数据的版本号已经修改为2 再次使用版本号1修改节点提交错误[zk: localhost:2181(CONNECTED) 16] set /mynode newdata02 1version No is not valid : /mynode delete：删除节点 1delete path [version] #语法格式 123456[zk: localhost:2181(CONNECTED) 17] delete /testnodeNode not empty: /testnode #拥有子节点，请先删除子节点[zk: localhost:2181(CONNECTED) 18] delete /testnode/sec0000000001[zk: localhost:2181(CONNECTED) 19] delete /testnode/sec0000000002[zk: localhost:2181(CONNECTED) 22] delete /testnode/sec0000000003[zk: localhost:2181(CONNECTED) 23] delete /testnode watcher通知机制 关于watcher机制大体的理解可以为，当每个节点发生变化，都会触发watcher事件，类似于mysql的触发器。zk中 watcher是一次性的，触发后立即销毁。 —stat path [watch] 设置watch事件 ； 12345678[zk: localhost:2181(CONNECTED) 24] stat /testwatch watchNode does not exist: /testwatch[zk: localhost:2181(CONNECTED) 25] create /testwatch test WATCHER::WatchedEvent state:SyncConnected type:NodeCreated path:/testwatchCreated /testwatch —get path [watch]设置watch事件 ； 1234567891011121314151617181920212223242526272829303132333435[zk: localhost:2181(CONNECTED) 27] create /testwatch2 aaaCreated /testwatch2#使用get命令添加watch事件[zk: localhost:2181(CONNECTED) 28] get /testwatch2 watchaaacZxid = 0x20000002dctime = Fri Jan 04 19:25:44 CST 2019mZxid = 0x20000002dmtime = Fri Jan 04 19:25:44 CST 2019pZxid = 0x20000002dcversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 0#修改节点触发watcher事件[zk: localhost:2181(CONNECTED) 29] set /testwatch2 newdataWATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/testwatch2cZxid = 0x20000002dctime = Fri Jan 04 19:25:44 CST 2019mZxid = 0x20000002emtime = Fri Jan 04 19:26:31 CST 2019pZxid = 0x20000002dcversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0#注：再次修改节点无法触发watcher时间，需要重新get /testwatch2 watch 添加触发。 —子节点创建和删除时触发watch事件，子节点修改不会触发该事件； ACL权限控制 ZK的节点有5种操作权限：CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限，这5种权限简写为crwda(即：每个单词的首字符缩写)。注：这5种权限中，delete是指对子节点的删除权限，其它4种权限指对自身节点的操作权限 身份的认证有4种方式： world：默认方式，相当于全世界都能访问 auth：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户) digest：即用户名:密码这种方式认证，这也是业务系统中最常用的 ip：使用Ip地址认证 3.3 四字命令Four Letter Words 使用四字命令需要安装nc命令,(yum install nc)； stat 查看状态信息： 12345678910111213[root@node01 ~]# echo stat | nc 192.168.142.11 2181Zookeeper version: 3.4.6-1569965, built on 02/20/2014 09:09 GMTClients: /192.168.142.11:43669[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/1/119Received: 552Sent: 554Connections: 1Outstanding: 0Zxid: 0x200000034Mode: followerNode count: 10 ruok 查看zookeeper是否启动 12[root@node01 ~]# echo ruok | nc 192.168.142.11 2181imok[root@node01 ~]# dump 列出没有处理的节点，临时节点 12345[root@node01 ~]# echo dump | nc 192.168.142.11 2181SessionTracker dump:org.apache.zookeeper.server.quorum.LearnerSessionTracker@44fc7eeeephemeral nodes dump:Sessions with Ephemerals (0): conf 查看服务器配置 123456789101112131415[root@node01 ~]# echo conf | nc 192.168.142.11 2181clientPort=2181dataDir=/opt/zookeeper/version-2dataLogDir=/opt/zookeeper/version-2tickTime=2000maxClientCnxns=60minSessionTimeout=4000maxSessionTimeout=40000serverId=1initLimit=10syncLimit=5electionAlg=3electionPort=3888quorumPort=2888peerType=0 cons 显示连接到服务端的信息 12[root@node01 ~]# echo cons | nc 192.168.142.11 2181 /192.168.142.11:43674[0](queued=0,recved=1,sent=0) envi 显示环境变量信息 1234567891011121314151617[root@node01 ~]# echo envi | nc 192.168.142.11 2181Environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMThost.name=node01java.version=1.8.0_191java.vendor=Oracle Corporationjava.home=/usr/java/jdk1.8.0_191-amd64/jrejava.class.path=/usr/zookeeper-3.4.6/bin/../build/classes:/usr/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/zookeeper-3.4.6/bin/../conf:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/libjava.io.tmpdir=/tmpjava.compiler=&lt;NA&gt;os.name=Linuxos.arch=amd64os.version=2.6.32-504.el6.x86_64user.name=rootuser.home=/rootuser.dir=/opt/hadoop/dfs mntr 查看zk的健康信息 12345678910111213141516[root@node01 ~]# echo mntr | nc 192.168.142.11 2181zk_version 3.4.6-1569965, built on 02/20/2014 09:09 GMTzk_avg_latency 1zk_max_latency 119zk_min_latency 0zk_packets_received 559zk_packets_sent 561zk_num_alive_connections 1zk_outstanding_requests 0zk_server_state followerzk_znode_count 10zk_watch_count 0zk_ephemerals_count 0zk_approximate_data_size 154zk_open_file_descriptor_count 30zk_max_file_descriptor_count 4096 wchs 展示watch的信息 123[root@node01 ~]# echo wchs | nc 192.168.142.11 21810 connections watching 0 pathsTotal watches:0 wchc和wchp 显示session的watch信息 path的watch信息，需要在 配置zoo.cfg文件中添加 4lw.commands.whitelist=*。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据005——HDFS1.0]]></title>
    <url>%2F2016%2F03%2F29%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE005%E2%80%94%E2%80%94HDFS1.0%2F</url>
    <content type="text"><![CDATA[HDFS即可作为Hadoop集群的一部分，也可以作为一个独立的分布式文件系统。上一小节实现了Hadoop安装，伪分布式搭建HDFS，这一小节使用完全分布式搭建Hadoop-HDFS系统。 1. 环境准备1.1 JDK安装并配置环境变量1echo $JAVA_HOME #查看JDK环境变量 1.2 准备至少3台Linux虚拟机、通过VMware的克隆虚拟机功能；配置好网络JDK 时间 hosts，保证节点间能互ping通，这里配置了host：node01、node02、node03。 1.3 时间同步查看之前小节。 1.4 ssh免秘钥登录查看之前小节。 2. 完全分布式搭建2.1 下载解压缩Hadoop1tar -zxvf hadoop-2.6.5.tar.gz 2.2 配置etc/hadoop/hadoop-env.sh1vim hadoop-2.6.5/etc/hadoop/hadoop-env.sh 添加JAVA/_HOME： 12export JAVA_HOME=$&#123;JAVA_HOME&#125;JAVA_HOME=/usr/java/jdk1.8.0_191-amd64 #这里为JDK根目录 2.3 配置core-site.xml1vim hadoop-2.6.5/etc/hadoop/core-site.xml fs.defaultFS 默认的服务端口NameNode URI ，hadoop.tmp.dir 是hadoop文件系统依赖的基础配置，很多路径都依赖它。如果hdfs-site.xml中不配置namenode和datanode的存放位置，默认就放在这个路径中： 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node01:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop-2.6.1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 2.4 配置hdfs-site.xmldfs.datanode.https.address表示https服务的端口； 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node02:50090&lt;/value&gt; &lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt; &lt;value&gt;node02:50091&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 2.5 配置Mastersmaster 表示可以做主备的SNN，在/home/hadoop-2.6.5/etc/hadoop/新建masters文件 写上SNN节点名： 1vim master 写入： 1node02 2.6 配置Slaves在/home/hadoop-2.6.5/etc/hadoop/slaves文件中填写DN 节点名：node01 node02 node03 （注意：每行写一个 写成3行）： 1vim slaves 写入： 123node01node02node03 2.7 最后将配置好的Hadoop通过SCP命令发送都其他节点12scp -r hadoop-2.6.5 node02:`pwd`scp -r hadoop-2.6.5 node03:`pwd` 2.8 配置Hadoop的环境变量1vim ~/.bash_profile 写入： 12export HADOOP_HOME=/home/hadoop-2.6.5export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 重新加载环境变量： 1source ~/.bash_profile 2.9 对NN进行格式化回到根目录（node01，这里指定了node01位namenode）对NN进行格式化： 1hdfs namenode -format 2.10 启动HDFS1start-dfs.sh 2.11 浏览器查阅关闭防火墙：service iptables stop； 在浏览器输入 node1:50070 出现以下界面成功：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据004——Hadoop]]></title>
    <url>%2F2016%2F03%2F28%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE004%E2%80%94%E2%80%94Hadoop%2F</url>
    <content type="text"><![CDATA[1. 前言Hadoop是一个开源框架，它允许在整个集群使用简单编程模型计算机的分布式环境存储并处理大数据。它的目的是从单一的服务器到上千台机器的扩展，每一个台机都可以提供本地计算和存储。 1.1 什么是大数据？大数据是不能用传统的计算技术处理的大型数据集的集合。它不是一个单一的技术或工具，而是涉及的业务和技术的许多领域。大数据包含通过不同设备和应用程序所产生的数据。如这些领域：黑匣子数据、社会化媒体数据、证券交易所数据、电网数据、交通运输数据、搜索引擎数据等。 大数据技术：大数据技术旨在提供更准确的分析，这可以影响更多的具体决策导致更大的效率、降低成本、并减少了对业务的风险。为了充分利用大数据的力量，需要管理和处理实时结构化和非结构化的海量数据，可以保护数据隐私和安全的基础设施。 操作大数据：包括像MongoDB系统，提供业务实时的能力，主要工作是数据捕获和存储互动。NoSQL大数据体系的设计充分利用已经在过去的十年，而让大量的计算，以廉价，高效地运行新的云计算架构的优势。这使得运营大数据工作负载更容易管理，更便宜，更快的实现。一些NoSQL系统可以提供深入了解基于使用最少的编码无需数据科学家和额外的基础架构的实时数据模式。 分析大数据：这些包括，如大规模并行处理（MPP）数据库系统和MapReduce提供用于回顾性和复杂的分析，可能触及大部分或全部数据的分析能力的系统。MapReduce提供分析数据的基础上，MapReduce可以按比例增加从单个服务器向成千上万的高端和低端机的互补SQL提供的功能，这是系统的一种新方法。 1.2 大数据解决方案 传统的企业方法 在这种方法中，一个企业将有一个计算机存储和处理大数据。对于存储而言，程序员会自己选择的数据库厂商，如Oracle，IBM等的帮助下完成，用户交互使用应用程序进而获取并处理数据存储和分析。 ​ 这种做法存在局限性：这种方式能完美地处理那些可以由标准的数据库服务器来存储，或直至处理数据的处理器的限制少的大量数据应用程序。但是，当涉及到处理大量的可伸缩数据，这是一个繁忙的任务，只能通过单一的数据库瓶颈来处理这些数据。 谷歌的解决方案 使用一种称为MapReduce的算法谷歌解决了这个问题。这个算法将任务分成小份，并将它们分配到多台计算机，并且从这些机器收集结果并综合，形成了结果数据集。 Hadoop 使用谷歌提供的解决方案，Doug Cutting和他的团队开发了一个开源项目叫做HADOOP。Hadoop使用的MapReduce算法运行，其中数据在使用其他并行处理的应用程序。总之，Hadoop用于开发可以执行完整的统计分析大数据的应用程序。 1.3 什么是Hadoop？Hadoop是使用Java编写，允许分布在集群，使用简单的编程模型的计算机大型数据处理的Apache的开源框架。Hadoop框架应用工程提供跨计算机集群的分布式存储和计算的环境。 Hadoop是专为从单一服务器到上千台机器扩展，每个机器都可以提供本地计算和存储。 在其核心，Hadoop主要有两个层次，即： 加工/计算层(MapReduce)，以及 存储层(Hadoop分布式文件系统) Hadoop的优势 Hadoop框架允许用户快速地编写和测试的分布式系统。有效并在整个机器和反过来自动分配数据和工作，利用CPU内核的基本平行度。 Hadoop不依赖于硬件，以提供容错和高可用性（FTHA），而Hadoop库本身已被设计在应用层可以检测和处理故障。 服务器可以添加或从集群动态删除，Hadoop可继续不中断地运行。 Hadoop的的另一大优势在于，除了是开源的，因为它是基于Java并兼容所有的平台。 Hadoop 生态系统 2. Hadoop HDFS——分布式文件存储系统Hadoop文件系统使用分布式文件系统设计开发。它是运行在普通硬件。不像其他的分布式系统，HDFS是高度容错以及使用低成本的硬件设计。HDFS拥有超大型的数据量，并提供更轻松地访问。为了存储这些庞大的数据，这些文件都存储在多台机器。这些文件都存储以冗余的方式来拯救系统免受可能的数据损失，在发生故障时。 HDFS也使得可用于并行处理的应用程序。 2.1 HDFS架构 2.2 HDFS 数据存储单元（block） 文件被切分成固定大小的数据块block 默认数据块大小为128MB (hadoop2.x)，可自定义配置； 若文件大小不到128MB ，则单独存成一个block； 一个文件存储方式 按大小被切分成若干个block ，存储到不同节点上； 默认情况下每个block都有3个副本； Block大小和副本数通过Client端上传文件时设置，文件上传成功后副本数可以变更，Block Size不可变更 hdfs存储模型：字节 文件线性切割成块（Block）:偏移量 offset （byte）；Block分散存储在集群节点中；单一文件Block大小一致，文件与文件可以不一致；Block可以设置副本数，副本分散在不同节点中； 副本数不要超过节点数量 文件上传可以设置Block大小和副本数；已上传的文件Block副本数可以调整，大小不变；只支持一次写入多次读取，同一时刻只有一个写入者；可以append追加数据。 2.3 NameNode NameNode主要功能： • 接受客户端的读/写服务 • 收集DataNode汇报的Block列表信息 基于内存存储 ：不会和磁盘发生交换 • 只存在内存中 • 持久化 NameNode保存metadata元数据信息 • 文件owership(归属)和permissions(权限) • 文件大小，时间 • （Block列表B1+B2+..：Block偏移量） • Block保存在哪个DataNode位置信息（由DataNode启动时上报,不保存） NameNode持久化 • NameNode的metadate信息在启动后会加载到内存 • metadata存储到磁盘文件名为”fsimage” • Block的位置信息不会保存到fsimage • edits记录对metadata的操作日志 fsimage保存了最新的元数据检查点,类似快照； editslog 保存自最新检查点后的元信息变化，从最新检查点后，hadoop将对每个文件的操作都保存在edits中。客户端修改文件时候，先写到editlog，成功后才更新内存中的metadata信息。 2.4 DataNode 本地磁盘目录存储数据（Block），文件形式； 同时存储Block的元数据信息文件； 启动DN进程的时候会向NameNode汇报block信息； 通过向NN发送心跳保持与其联系（3秒一次），如果NN 10分钟没有收到DN的心跳，则认为其已经lost，并copy其上的block到其它DN。 2.5 SecondaryNameNode它的主要工作是帮助NN合并edits log文件，减少NN启动时间,它不是NN的备份（但可以做备份)。 SNN执行合并时间和机制： 根据配置文件设置的时间间隔fs.checkpoint.period 默认3600秒。 根据配置文件设置edits log大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB 2.6 SecondaryNameNode SNN合并流程 首先是NN中的Fsimage和edits文件通过网络拷贝，到达SNN服务器中，拷贝的同时，用户的实时在操作数据，那么NN中就会从新生成一个edits来记录用户的操作，而另一边的SＮＮ将拷贝过来的edits和fsimage进行合并，合并之后就替换NN中的fsimage。之后NN根据fsimage进行操作（当然每隔一段时间就进行替换合并，循环）。当然新的edits与合并之后传输过来的fsimage会在下一次时间内又进行合并。 2.7 Block的副本放置策略 第一个副本：放置在上传文件的DN；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。 第二个副本：放置在于第一个副本不同的机架的节点上。 第三个副本：与第二个副本相同机架的不同节点。 更多副本：随机节点 2.8 HDFS读写流程2.8.1 在HDFS读操作数据读取请求将由 HDFS，NameNode和DataNode来服务。让我们把读取器叫 “客户”。下图描绘了文件的读取操作在 Hadoop 中： 客户端启动通过调用文件系统对象的 open() 方法读取请求; 它是 DistributedFileSystem 类型的对象。 此对象使用 RPC 连接到 namenode 并获取的元数据信息，如该文件的块的位置。 请注意，这些地址是文件的前几个块。 响应该元数据请求，具有该块副本的 DataNodes 地址被返回。 一旦接收到 DataNodes 的地址，FSDataInputStream 类型的一个对象被返回到客户端。 FSDataInputStream 包含 DFSInputStream 这需要处理交互 DataNode 和 NameNode。在上图所示的步骤4，客户端调用 read() 方法，这将导致 DFSInputStream 建立与第一个 DataNode 文件的第一个块连接。 以数据流的形式读取数据，其中客户端多次调用 “read() ” 方法。 read() 操作这个过程一直持续，直到它到达块结束位置。 一旦到模块的结尾，DFSInputStream 关闭连接，移动定位到下一个 DataNode 的下一个块 一旦客户端已读取完成后，它会调用 close()方法。 2.8.2 在HDFS写操作 客户端通过调用 DistributedFileSystem对象的 create() 方法创建一个新的文件，并开始写操作 - 在上面的图中的步骤1 DistributedFileSystem对象使用 RPC 调用连接到 NameNode，并启动新的文件创建。但是，此文件创建操作不与文件任何块相关联。NameNode 的责任是验证文件(其正被创建的)不存在，并且客户端具有正确权限来创建新文件。如果文件已经存在，或者客户端不具有足够的权限来创建一个新的文件，则抛出 IOException 到客户端。否则操作成功，并且该文件新的记录是由 NameNode 创建。 一旦 NameNode 创建一条新的记录，返回FSDataOutputStream 类型的一个对象到客户端。客户端使用它来写入数据到 HDFS。数据写入方法被调用(图中的步骤3)。 FSDataOutputStream包含DFSOutputStream对象，它使用 DataNodes 和 NameNode 通信后查找。当客户机继续写入数据，DFSOutputStream 继续创建这个数据包。这些数据包连接排队到一个队列被称为 DataQueue 还有一个名为 DataStreamer 组件，用于消耗DataQueue。DataStreamer 也要求 NameNode 分配新的块，拣选 DataNodes 用于复制。 现在，复制过程始于使用 DataNodes 创建一个管道。 在我们的例子中，选择了复制水平3，因此有 3 个 DataNodes 管道。 所述 DataStreamer 注入包分成到第一个 DataNode 的管道中。 在每个 DataNode 的管道中存储数据包接收并同样转发在第二个 DataNode 的管道中。 另一个队列，“Ack Queue”是由 DFSOutputStream 保持存储，它们是 DataNodes 等待确认的数据包。 一旦确认在队列中的分组从所有 DataNodes 已接收在管道，它从 ‘Ack Queue’ 删除。在任何 DataNode 发生故障时，从队列中的包重新用于操作。 在客户端的数据写入完成后，它会调用close()方法(第9步图中)，调用close()结果进入到清理缓存剩余数据包到管道之后等待确认。 一旦收到最终确认，NameNode 连接告诉它该文件的写操作完成。 3. Hadoop安装（伪分布式搭建）3.1 jdk安装，配置环境变量jdk安装略过，配置环境变量（局部变量版）： 1[root@node01 html]# vim ~/.bash_profile 插入： 12JAVA_HOME=/usr/java/jdk1.8.0_191-amd64PATH=$PATH:$JAVA_HOME/bin 3.2 ssh免密钥（本机）SSH设置需要在集群上做不同的操作，如启动，停止，分布式守护shell操作。认证不同的Hadoop用户，需要一种用于Hadoop用户提供的公钥/私钥对，并用不同的用户共享。 下面的命令用于生成使用SSH键值对。复制公钥形成 id_rsa.pub 到authorized_keys 文件中，并提供拥有者具有authorized_keys文件的读写权限。 12ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsacat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 3.3 上传hadoop.tar.gz到服务器 解压部署包到指定安装目录下； 在~/.bashrc 文件中设置 Hadoop 环境变量： 12export HADOOP_PREFIX=/usr/hadoop-2.6.5PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin 确保Hadoop安装正常： 1[root@node01 www.shsxt.com]# hadoop version 会出现： 123456Hadoop 2.6.5Subversion Unknown -r UnknownCompiled by root on 2017-05-24T14:32ZCompiled with protoc 2.5.0From source with checksum f05c9fa095a395faa9db9f7ba5d754This command was run using /usr/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar Hadoop配置 找到位置“$HADOOP_HOME/etc/hadoop”下找到所有Hadoop配置文件，这是需要根据Hadoop基础架构进行更改这些配置文件： 配置hadoop-env.sh：为了使用Java开发Hadoop程序，必须用java在系统中的位置替换JAVA_HOME值并重新设置hadoop-env.sh文件的java环境变量： 1JAVA_HOME=/usr/java/jdk1.8.0_191-amd64 配置core-site.xml：core-site.xml文件中包含如读/写缓冲器用于Hadoop的实例的端口号的信息，分配给文件系统存储，用于存储所述数据存储器的限制和大小： 12345678910&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;!-- hadoop所在系统IP，或localhost，或host主机名 --&gt; &lt;value&gt;hdfs://node01:9000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;!-- 指定中转文件夹 --&gt; &lt;value&gt;/opt/hadooplocal&lt;/value&gt;&lt;/property&gt; 配置hdfs-site.xml：hdfs-site.xml 文件中包含如复制数据的值，NameNode路径的信息，本地文件系统的数据节点的路径，这意味着是存储Hadoop基础工具的地方： 123456789&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;!-- 副本个数，默认3个 --&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node01:50090&lt;/value&gt; &lt;/property&gt; 配置slaves（datanode节点）： 1node01 格式化 hdfs ： 1hdfs namenode -format 启动 1start-dfs.sh 查看服务进程启动了么？ jps a) SecondaryNameNode b) NameNode c) DataNode d) Jps 访问 node01:50070 （windows指定了host主机明和IP），确保防火墙关闭（service iptables stop）； 显示如下数据： 3.4 hdfs dfs指令 hdfs dfs -mkdir /user：创建文件夹user； hdfs dfs -ls /user：遍历列举文件夹user； hdfs dfs -put fileName[本地文件名] PATH[hdfs的文件路径]：上传文件； hdfs dfs -du [-s][-h]URI[URI …] 显示文件(夹)大小； hdfs dfs -rm -r /user ：删除文件夹user； hdfs dfs -get fileName[hdf的文件名] PATH[指定本地路径及文件名]：下载文件； 3.5 hdfs dfs测试 准备本地待存储的文件： 产生100000条数据：for i in seq 100000;do echo “hello hadoop $i” &gt;&gt; test.txt;done 1-rw-r--r--. 1 root root 1888895 Dec 23 03:36 test.txt 容量为1.8MB； 上传至hdfs： 1[root@node01 ~]# hdfs dfs -put test.txt /user/text01.txt 显示： 123[root@node01 ~]# hdfs dfs -ls /userFound 1 items-rw-r--r-- 3 root supergroup 1888895 2018-12-23 03:38 /user/text01.txt 默认数据块大小为128MB，所以只分配一个block块； 指定block大小为1MB上传文件： 1[root@node01 ~]# hdfs dfs -D dfs.blocksize=1048576 -put test.txt /user/test02.txt 显示： 1234[root@node01 ~]# hdfs dfs -ls /userFound 2 items-rw-r--r-- 3 root supergroup 1888895 2018-12-23 03:48 /user/test02.txt-rw-r--r-- 3 root supergroup 1888895 2018-12-23 03:38 /user/text01.txt 因为指定了block块大小为1MB，所以分配了两个block块。 4. Windows下Java开发环境整合hdfs4.1 windows上部署hadoop包 解压部署hadoop包； bin目录下需具备如下文件： 将bin目录下的hadoop.dll 放到 c:/windows/system32下； windows环境变量配置: HADOOP_HOME = F:\hadoop-2.6.5 HADOOP_USER_NAME = root eclipse插件：将以hadoop-eclipse-plugin-2.6.0.jar包放入eclipse的plugins文件夹中； 启动eclipse：出现界面如下： 新建Location： 建立连接成功： 4.2 HDFS API测试：请将linux下hadoop中：core-site.xml与hdfs-site.xml文件导入到java项目src目录下； 创建测试类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132public class HdfsTest &#123; private static Configuration config; private static FileSystem fs; public static void main(String[] args) throws IOException &#123;// 实例化配置 config = new Configuration(); fs = FileSystem.get(config);// 创建删除文件夹目录// mk_deldir(); // 上传文件// uploadfiles(); // 下载文件// downloadfiles(); // 查看文件详细信息 ListFilestatus(); // 合并小文件到hdfs// seqfile();// block(); &#125; private static void seqfile() throws IOException &#123; File dir = new File("D:/123"); Path path = new Path("/jjcc/seq123"); SequenceFile.Writer writer = SequenceFile.createWriter(fs, config, path, Text.class, Text.class, CompressionType.NONE); for (File ff : dir.listFiles()) &#123; writer.append(new Text(ff.getName()), new Text(FileUtils.readFileToString(ff, "utf-8"))); &#125; System.out.println("success !"); &#125; private static void ListFilestatus() throws FileNotFoundException, IOException &#123; Path path = new Path("/java22"); FileStatus[] fileStatus = fs.listStatus(path); for (int i = 0; i &lt; fileStatus.length; i++) &#123; FileStatus status = fileStatus[i]; System.out.println( status.getOwner()+"\t"+ status.getAccessTime()+"\t"+ status.getModificationTime()+"\t"+ status.getBlockSize()/1024/1024+"MB \t"+ status.getPath() ); &#125; &#125; private static void downloadfiles() throws IOException &#123;// 要下载的源数据文件放在哪 File files = new File("D:/hadoopDownload/11.pdf");// 要下载的数据到hdfs的哪个地方 Path path = new Path("/java22/1.3");// 流 下载==读流程 FSDataInt.. FSDataInputStream in = fs.open(path); FileOutputStream out = new FileOutputStream(files); IOUtils.copyBytes(in, out, config); System.out.println("下载成功"); &#125; private static void uploadfiles() throws IOException &#123;// 要上传的源数据文件在哪 File files = new File("D:/大数据001——Linux.pdf");// 要上传到hdfs的哪个地方 Path path = new Path("/java22/1.3");// 流 上传==写流程 FSDataOut.. FSDataOutputStream out = fs.create(path); IOUtils.copyBytes(new FileInputStream(files), out, config); System.out.println("上传成功"); &#125; private static void mk_deldir() throws IOException &#123;// 指定要创建的目录路径 Path path = new Path("/java22"); if(fs.exists(path))&#123; fs.delete(path,true); System.out.println("文件目录存在 已删除"); &#125; fs.mkdirs(path); System.out.println("创建文件夹目录操作成功~"); &#125; private static void block() throws IOException &#123; Path ifile = new Path("/jjcc/test.txt"); FileStatus file = fs.getFileStatus(ifile );// 获取block的location信息 HDFS分布式文件存储系统根据其偏移量的位置信息来读取其内容 BlockLocation[] blk = fs.getFileBlockLocations(file , 0, file.getLen());// for (BlockLocation bb : blk) &#123;// System.out.println(bb);// &#125; FSDataInputStream input = fs.open(ifile);// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());// System.out.println((char)input.readByte());//// 指定从哪个offset的位置偏移量来读 input.seek(1048576); System.out.println((char)input.readByte()); System.out.println((char)input.readByte()); System.out.println((char)input.readByte()); input.seek(1048576); System.out.println((char)input.readByte()); System.out.println((char)input.readByte()); &#125;&#125; 结果：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据003——nginx]]></title>
    <url>%2F2016%2F03%2F27%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE003%E2%80%94%E2%80%94nginx%2F</url>
    <content type="text"><![CDATA[1. 虚拟主机虚拟主机是指在网络服务器上分出一定的磁盘空间，用户可以租用此部分空间，以供用户放置站点及应用组件，提供必要的数据存放和传输功能。 nginx可以配置基于域名和基于端口的虚拟主机： 1.1 基于域名的虚拟主机编辑/usr/local/nginx/conf（注意是安装目录，非源码包目录）下的nginx.conf： 123456789101112131415161718192021222324http &#123; upstream web01&#123; server node02; &#125; upstream web02&#123; server node03; &#125; server &#123; listen 80; //访问mydomain1.com的时候，会把请求导到web01的服务器组里 server_name mydomain1.com; location / &#123; proxy_pass http://web01; &#125; &#125; server &#123; listen 80; //访问mydomain2.com的时候，会把请求导到web02的服务器组里 server_name mydomain2.com; location / &#123; proxy_pass http://web02; &#125; &#125; &#125; 基于域名的虚拟机主机 在模拟应用场景时，需要在windows系统的hosts文件里配置域名映射。 编辑C:\Windows\System32\drivers\etc\下的hosts文件： 12192.168.142.11 mydomain1.com192.168.142.11 mydomain2.com 注意：已在Linux虚拟机端/etc/下的hosts编辑： 123192.168.142.11 node01192.168.142.12 node02192.168.142.13 node03 启动nginx后，分别访问mydomain1.com ,mydomain2.com： 1.2 基于端口的虚拟主机编辑/usr/local/nginx/conf（注意是安装目录，非源码包目录）下的nginx.conf： 123456789101112131415161718192021222324http &#123; upstream web01&#123; server node02; &#125; upstream web02&#123; server node03 &#125; server &#123; //当访问nginx的80端口时，将请求导给bjsxt组 listen 81; server_name localhost; location / &#123; proxy_pass http://web01; &#125; &#125; server &#123; //当访问nginx的81端口时，将请求导给shsxt组 listen 82; server_name localhost; location / &#123; proxy_pass http://web02; &#125; &#125; &#125; 启动nginx后，分别访问192.168.142.11（nginx服务器IP，也即node01）的81端口和82端口： 1.3 正向代理和反向代理请自行理解。 1.4 Nginx的session的一致性问题1. Session一致性解决方案a. session复制, tomcat 本身带有复制session的功能。 b. 共享session, 需要专门管理session的软件，memcached 缓存服务，可以和tomcat整合，帮助tomcat共享管理session。 2. 安装memcached 安装memcached内存数据库 1yum -y install memcached web服务器连接memcached的jar包拷贝到tomcat的lib，本文用的是Tomcat7对应的jar包： 配置tomcat的conf目录下的context.xml： 12345678&lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" &lt;!--memcached所在虚拟机IP--&gt; memcachedNodes="n1:192.168.xxx.xxx:11211" sticky="true" lockingMode="auto" sessionBackupAsync="false" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"sessionBackupTimeout="1000" transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" /&gt; 配置memcachedNodes属性，配置memcached数据库的ip和端口，默认11211，多个的话用逗号隔开。目的是为了让tomcat服务器从memcached缓存里面拿session或者是放session。 修改index.jsp，取sessionid看一看： 12345678&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;html lang="en"&gt;SessionID:&lt;%=session.getId()%&gt;&lt;/br&gt;SessionIP:&lt;%=request.getServerName()%&gt;&lt;/br&gt;&lt;h1&gt;tomcat1&lt;/h1&gt;&lt;/html&gt; 启动memcached： 1memcached -d -m 128m -p 11211 -l 192.168.xxx.xxx -u root -P /tmp/ 访问不同Tomcat服务器：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据002——Linux、nginx]]></title>
    <url>%2F2016%2F03%2F26%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE002%E2%80%94%E2%80%94Linux%E3%80%81nginx%2F</url>
    <content type="text"><![CDATA[1. 服务操作列出所有服务：chkconfig； ​ 各数字代表的系统初始化级别含义： ​ 0：停机状态 1：单用户模式，root账户进行操作 2：多用户，不能使用net file system，一般很少用 3：完全多用户，一部分启动，一部分不启动，命令行界面 4：未使用、未定义的保留模式 5：图形化，3级别中启动的进程都启动，并且会启动一部分图形界面进程。 6：停止所有进程，卸载文件系统，重新启动(reboot) 服务操作：service 服务名 start/stop/status/restart； 关闭防火墙：service iptables start/stop/status； 服务初执行等级更改：chkconfig –level 2345 name off|on 2. linux进程操作查看所有进程：ps -aux ​ -a 列出所有 ​ -u 列出用户 ​ -x 详细列出，如cpu、内存等 ​ ps - ef | grep XXX； 杀死进程：kill pid ​ -9：强制杀死； 3. 其他常用命令yum：是一个在Fedora和RedHat以及CentOS中的Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装。 wget： 是一个从网络上自动下载文件的自由工具，支持通过 HTTP、HTTPS、FTP 三个最常见的 TCP/IP协议 下载，并可以使用 HTTP 代理 需先安装 yum install wget –y wget用法:wget [option] 网址 ​ -O 指定下载保存的路径 tar包： ​ -z gzip进行解压或压缩，带.gz需要加，压缩出来.gz也需要加 ​ -x 解压 ​ -c 压缩 ​ -f 目标文件，压缩文件新命名或解压文件名 ​ -v 解压缩过程信息打印 解压命令：tar -zvxf xxxx.tar.gz。 4. JDK部署 上传并解压： 指定目录安装：.tar.gz文件,如在/usr/soft/目录下tar -zxf jdk-7u80-linux-x64.tar.gz； 默认路径安装：.rpm文件，如任意目录下rpm -inf jdk-7u80-linux-x64.rpm ,默认安装到/usr/java目录; 配置环境变量 第一种方式（全局变量）：vim /etc/profile 12JAVA_HOME= /usr/soft/jdk1.7.0_75PATH=$PATH:$JAVA_HOME/bin source /etc/profile 第二种方式（局部变量）：vim ~/.bash_profile 12JAVA_HOME= /usr/soft/jdk1.7.0_75PATH=$PATH:$JAVA_HOME/bin source ./bash_profile 验证 java -version。 5. 部署Tomcat上传并解压：apache-tomcat-7.0.61.tar.gz； 启动tomcat：bin目录下 ./startup.sh； 显示当前所有java进程：jps 126034 Jps5966 Bootstrap 6. nginxweb应用在海量并发的环境下，用户每一次请求服务器，都需要大量的创建线程，每一次的线程都必须分配资源（CPU、内存、带宽、磁盘IO等），当资源不足的时候就会使得服务器宕机而无法提供服务。Nginx (engine x) 是一个高性能的HTTP和反向代理服务其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。 6.1 负载均衡Nginx可以通过反向代理来实现负载均衡。 6.2 安装Nginx 依赖 gcc openssl-devel pcre-devel zlib-devel 安装：yum -y install gcc openssl-devel pcre-devel zlib-devel； 解压：tar -zxvf nginx-1.8.1.tar.gz； 进入解压后的源码目录：./configure； 编译并安装：make &amp;&amp; make install，默认安装目录：/usr/local/nginx； 配置Nginx为系统服务，以方便管理，在/etc/rc.d/init.d/目录中建立文本文件nginx，在文件中粘贴下面的内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0 nginx="/usr/local/nginx/sbin/nginx"prog=$(basename $nginx) NGINX_CONF_FILE="/usr/local/nginx/conf/nginx.conf" [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`nginx -V 2&gt;&amp;1 | grep "configure arguments:" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; configtest || return $? stop sleep 1 start&#125; reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 修改nginx文件的执行权限：chmod +x nginx； 添加该文件到系统服务中去：chkconfig –add nginx​ 查看是否添加成功：chkconfig –list nginx； 启动，停止，重新装载：service nginx start|stop； 本地物理机访问：IP地址+80端口，出现如下界面： 6.3 Nginx默认配置详解1234567891011121314151617181920212223242526272829303132333435#进程数，建议设置和CPU个数一样或2倍worker_processes 2;#日志级别error_log logs/error.log warning;(默认error级别)# nginx 启动后的pid 存放位置#pid logs/nginx.pid;events &#123; #配置每个进程的连接数，总的连接数= worker_processes * worker_connections #默认1024 worker_connections 10240;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on;#连接超时时间，单位秒keepalive_timeout 65; server &#123; listen 80; server_name localhost #默认请求 location / &#123; root html; #定义服务器的默认网站根目录位置 index index.php index.html index.htm; #定义首页索引文件的名称 &#125; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 6.4 负载均衡配置nginx支持以下负载均衡机制（或方法）： a) 轮询负载均衡 - 对应用程序服务器的请求以循环方式分发， b) 加权负载均衡 c) 最少连接数 - 将下一个请求分配给活动连接数最少的服务器 d) ip-hash - 哈希函数用于确定下一个请求（基于客户端的IP地址）应该选择哪个服务器。 6.4.1 默认负载平衡配置使用nginx进行负载平衡的最简单配置可能如下所示： 123456789101112131415http &#123; upstream myserver&#123; server node01; server node02; server node03; &#125; server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://myserver; &#125; &#125; &#125; 6.4.2 加权负载平衡通过使用服务器权重，还可以进一步影响nginx负载均衡算法，谁的权重越大，分发到的请求就越多。 12345 upstream myserver &#123;server srv1.example.com weight=3;server srv2.example.com; server srv3.example.com; &#125; 6.4.3 最少连接负载平衡在连接负载最少的情况下，nginx会尽量避免将过多的请求分发给繁忙的应用程序服务器，而是将新请求分发给不太繁忙的服务器，避免服务器过载。 123456upstream myserver &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 6.4.4 会话持久性使用ip-hash，客户端的IP地址将用作散列键，以确定应该为客户端的请求选择服务器组中的哪台服务器。此方法可确保来自同一客户端的请求将始终定向到同一台服务器，除非此服务器不可用。 123456upstream myserver&#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; 6.5 Nginx的访问控制Nginx还可以对IP的访问进行控制，allow代表允许，deny代表禁止。 12345678location / &#123; deny 192.168.2.180; allow 192.168.78.0/24; allow 10.1.1.0/16; allow 192.168.1.0/32; deny all; proxy_pass http://myserver;&#125; 从上到下的顺序，匹配到了便跳出。如上的例子先禁止了1个，接下来允许了3个网段，其中包含了一个ipv6，最后未匹配的IP全部禁止访问。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据001——Linux]]></title>
    <url>%2F2016%2F03%2F25%2Fmd_%E5%A4%A7%E6%95%B0%E6%8D%AE%2F%E5%A4%A7%E6%95%B0%E6%8D%AE001%E2%80%94%E2%80%94Linux%2F</url>
    <content type="text"><![CDATA[1. 环境准备1.1 VMware安装虚拟机VMware10。 1.2 Linux安装安装CentOS6.6。 1.3 网络配置1.3.1 查看虚拟机网关 在此之前linux系统的虚拟机网络设置为NAT模式： 一般虚拟机网关为 .2 结尾，如本机：192.168.142.2； 起始——结束IP地址设置为：192.168.142.4——192.168.142.254， .0/.1/.2/.255一般为专用IP。 1.3.2 配置Liunx静态IP(NAT模式) Ⅰ. 编辑配置文件Linux命令行输入： 1[root@node01 ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0 按i 进入文本编辑模式，出现游标，左下角会出现INSERT,即可以编辑: 12345678DEVICE=eth0 #网卡设备名,请勿修改名字 TYPE=Ethernet #网络类型，以太网 ONBOOT=yes #开启自动启用网络连接NM_CONTROLLED=yesBOOTPROTO=static #启用静态IP地址IPADDR=192.168.142.11 #设置IP地址NETMASK=255.255.255.0 #设置子网掩码GATEWAY=192.168.142.2 #设置网关 按ESC退出编辑模式，输入:wq 保存退出； Ⅱ. 修改完后执行以下命令1[root@node01 ~]# service network restart #重启网络连接 Ⅲ. 验证是否配置成功 a. 虚拟机能ping通虚拟网关 12345678[root@node01 ~]# ping 192.168.142.2PING 192.168.142.2 (192.168.142.2) 56(84) bytes of data.64 bytes from 192.168.142.2: icmp_seq=1 ttl=128 time=8.48 ms64 bytes from 192.168.142.2: icmp_seq=2 ttl=128 time=0.325 ms^C--- 192.168.142.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1959msrtt min/avg/max/mdev = 0.325/4.404/8.484/4.080 ms Ctrl键+C停止。 b. 虚拟机与物理机（笔记本）相互可ping通 123456789[root@node01 ~]# ping 192.168.4.180PING 192.168.4.180 (192.168.4.180) 56(84) bytes of data.64 bytes from 192.168.4.180: icmp_seq=1 ttl=128 time=0.781 ms64 bytes from 192.168.4.180: icmp_seq=2 ttl=128 time=0.485 ms64 bytes from 192.168.4.180: icmp_seq=3 ttl=128 time=0.435 ms^C--- 192.168.4.180 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2239msrtt min/avg/max/mdev = 0.435/0.567/0.781/0.152 ms Ctrl键+C停止。 c. 虚拟机与公网上的百度网址相互可ping通（此步ping通，才说明网络配置成功） ​ 命令：ping www.baidu.com 在此之前需要配置DNS服务器的地址文件，Linux命令行输入： 1[root@node01 ~]# vi /etc/resolv.conf 按i 进入文本编辑模式，输入： 1nameserver 192.168.142.2 #虚拟机网关 ping公网百度： 12345678910[root@node01 ~]# ping www.baidu.comPING www.a.shifen.com (115.239.210.27) 56(84) bytes of data.64 bytes from 115.239.210.27: icmp_seq=1 ttl=128 time=13.8 ms64 bytes from 115.239.210.27: icmp_seq=2 ttl=128 time=14.6 ms64 bytes from 115.239.210.27: icmp_seq=3 ttl=128 time=13.0 ms64 bytes from 115.239.210.27: icmp_seq=4 ttl=128 time=13.8 ms^C--- www.a.shifen.com ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3350msrtt min/avg/max/mdev = 13.066/13.864/14.678/0.582 ms 1.3.3 XShell xftp安装与使用安装XShell。 2. Linux文件系统Linux文件系统中的文件是数据的集合，文件系统不仅包含着文件中的数据而且还有文件系统的结构，所有Linux 用户和程序看到的文件、目录、软连接及文件保护信息等都存储在其中。 2.1 目录操作切换目录：cd + 目录的路径； ​ cd / ：进入/目录，该目录下存在 bin、boot、dev、etc、home、lib、proc、usr、var等文件夹； ​ cd /usr：进入到usr文件夹目录； ​ cd ~ ：进入到root目录。 查看当前目录的完整路径 ：pwd； 返回到父目录： cd ..； 新建目录：mkdir + 目录名字； 查看当前目录下拥有的子目录和文件: ls； 查看当前目录下拥有的子目录和文件: ll，长列表格式显示文件及目录； 拷贝目录：cp source dest -rf； ​ -f：强制的； ​ -v：递归的、遍历的； 删除目录：rmdir directory、rm-rf dir； 移动/更改 目录：mv + 目录/文件名字 + 其他路径、mv test / 将test目录移动到根目录/ 下； 2.2 文件操作新建文件（一切皆文件）：touch web.log 创建一个空文件； 复制文件：cp -rf web.log web_cp.log； 删除文件：**rm -f web_cp.log； 查看目录下的东西：ls / ll； 查看目录下的所有东西（包括隐藏文件）：ls –al 等价于 ll –a； 查看文件内容：cat filename 一次性显示整个文件的内容 more filename 该命令一次显示一屏文本，满屏后停下来，并且在屏幕的底部出现一个提示信息，给出至今己显示的该文件的百分比。 ​ 按Space键，显示文本的下一屏内容。 按Enier键，只显示文本的下一行内容。 ​ 按B键，显示上一屏内容。 ​ 按Q键，退出。 less命令 与 more命令非常类似； 从头打印文件内容：head -10 filename 打印文件1到10行； 从尾部打印文件内容：tail -10 filename 打印文件最后10行； 查找文件或目录：find pathname –name filename； ​ find /etc -name pro*：查找以pro开头的文件或目录； 2.3 文本编辑vi编辑模式 ​ vi filename :打开或新建文件，并将光标置于第一行首 ； ​ vi +n filename ：打开文件，并将光标置于第n行首 ； ​ vi + filename ：打开文件，并将光标置于最后一行首 ； ​ vi +/pattern filename：打开文件，并将光标置于第一个与 pattern匹配的串处； vi命令行模式 ​ w保存 ​ q退出 ​ q!：不保存文件并退出vi ​ – 在VI的命令模式下输入“:set nu”，就有行号了。 ​ – 在VI的命令模式下输入“:set nonu”，取消行号。 一般模式 yy 复制光标所在行(常用) ​ nyy 复制光标所在行的向下n行，例如， 20yy则是复制20行(常用) p,P p为复制的数据粘贴在光标下一行， P则为粘贴在光标上一行(常用) ​ G:光标移至第最后一行 ​ nG：光标移动至第N行行首 ​ n+：光标下移n行 ​ n-：光标上移n行 ​ H ：光标移至屏幕顶行 ​ M ：光标移至屏幕中间行 ​ L ：光标移至屏幕最后行 dd：删除 行 ​ x或X：删除一个字符，x删除光标后的，而X删除光标前的 u 恢复前一个动作(常用) ​ 删除第N行到第M行：N,Md vim编辑器 ​ 安装vim：yum install vim -y； 2.4 文件传输将本地文件复制到远程机器：scp local_file remote_username@remote_ip:remote_folder； 将本地目录复制到远程机器：scp -r local_folder remote_username@remote_ip:remote_folder； 文件上传需先安装好lrzsz : yum install lrzsz -y； 安装好后，输入上传的命令rz,弹出上传文件选择界面； 将文件下载至windows系统：sz filename； 3. 网络指令查看网络配置信息：ifconfig； 测试与目标主机的连通性：ping remote_ip； 显示各种网络相关信息：netstat –a n p t； ​ -a (all)显示所有选项，默认不显示LISTEN相关 -t (tcp)仅显示tcp相关选项​ -u (udp)仅显示udp相关选项​ -n 拒绝显示别名，能显示数字的全部转化成数字。 -l 仅列出有在 Listen (监听) 的服務状态 ​ -p 显示建立相关链接的程序名​ -r 显示路由信息，路由表​ -e 显示扩展信息，例如uid等​ -s 按各个协议进行统计 -c 每隔一个固定时间，执行该netstat命令。 ​ 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到； 注意：当进行了克隆或回到快照（VMware功能）操作，重新配置了系统IP后，需要删除规则文件并重启系统： 1rm -rf /etc/udev/rules.d/70-persistent-n 4. 系统配置主机名配置：vim /etc/sysconfig/network； 12NETWORKING=yesHOSTNAME=node01 #在此修改主机名 IP地址hostname的对应：vi /etc/hosts； 1234127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.142.11 node01 #编辑IP和对应的主机名192.168.142.12 node02 之后便可以直接ping 主机名测试网络连接； DNS配置：/etc/resolv.conf； 1nameserver 192.168.142.2 #也可以配置nameserver 114.114.114.114 环境变量：Linux系统的环境变量是在/etc/profile文件里配置； 查看系统所有的环境变量和对应的目录：echo $path； 编辑环境变量：vim /etc/profile； 重新加载环境：source /etc/profile；]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB数据库基本语法练习——查询篇]]></title>
    <url>%2F2016%2F01%2F25%2Fmd_%E6%95%B0%E6%8D%AE%E5%BA%93%2FMongoDB%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E7%BB%83%E4%B9%A0%E2%80%94%E2%80%94%E6%9F%A5%E8%AF%A2%E7%AF%87%2F</url>
    <content type="text"><![CDATA[MongoDB是一个介于关系型数据库和菲关系型数据库之间的产品，其最大的特点是它支持的查询语言非常强大，且其语法有点类似面向对象的查询语言几乎可以实现类似关系型数据库单表查询的绝大部分功能。下面是我本人练习MongoDB数据库基本语法（查询篇）的JavaScript代码（编辑环境：Robo 3T-1.2 绿色版）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840/***************批量插入数据*****************/user1 = &#123; "_id":1, "name":"zhangsan", "age":1, "hobbies":["music", "read"], "addr":&#123; "country":"China", "city":"BJ" &#125;&#125;user2 = &#123; "_id":2, "name":"lisi", "age":2, "hobbies":["music", "read"], "addr":&#123; "country":"China", "city":"SH" &#125;&#125;user3 = &#123; "_id":3, "name":"wangwu", "age":3, "hobbies":["music", "read"], "addr":&#123; "country":"China", "city":"GZ" &#125;&#125;user4 = &#123; "_id":4, "name":"zhaoliu", "age":4, "hobbies":["music", "read"], "addr":&#123; "country":"China", "city":"SZ" &#125;&#125;user5 = &#123; "_id":5, "name":"tianqi", "age":5, "hobbies":["music", "read"], "addr":&#123; "country":"China", "city":"TY" &#125;&#125;db.user.insertMany([user1, user2, user3, user4, user5])/** *1、查询所有 */db.ser.find() //等同于db.user.find(&#123;&#125;)db.user.distinct("age")//去重db.user.find().pretty()//格式化的方式来显示所有文档//select * from user where id != 3/** *3、比较查询 * =，!= ('$ne') ，&gt; ('$gt') ，&lt; ('$lt') ，&gt;= ('$gte') ，&lt;= ('$lte') *///select * from user where id = 3db.user.find(&#123;"_id":3&#125;)//select * from user where id != 3db.user.find(&#123;"_id":&#123;"$ne":3&#125;&#125;)//select * from user where id &gt; 3db.user.find(&#123;"_id":&#123;"$gt":3&#125;&#125;) //select * from user where age &lt; 3db.user.find(&#123;"_id":&#123;"$lt":3&#125;&#125;)//select * from user where id &gt;= 3db.user.find(&#123;"_id":&#123;"$gte":3&#125;&#125;)//select * from user where id &lt;= 3db.user.find(&#123;"_id":&#123;"$lte":3&#125;&#125;)/** *3、逻辑查询 * $and,$or,$not */// select * from user where id &gt;=3 and id &lt;=4;db.user.find(&#123;"_id":&#123;"$gte":3,"$lte":4&#125;&#125;)// select * from user where id &gt;=3 and id &lt;=4 and age &gt;=4;db.user.find(&#123; "_id":&#123;"$gte":3,"$lte":4&#125;, "age":&#123;"$gte":4&#125;&#125;)db.user.find(&#123; "$and": [ &#123;"_id": &#123;"$gte":3, "$lte":4&#125;&#125;, &#123;"age": &#123;"$gte":4&#125;&#125; ]&#125;)// select * from user where id &gt;=0 and id &lt;=1 or id &gt;=4 or name = "tianqi";db.user.find(&#123; $or: [ &#123;"_id": &#123;$gte:0, $lte:1&#125;&#125;, &#123;"_id": &#123;$lte:4&#125;&#125;, &#123;"name": "tianqi"&#125; ]&#125;)// select * from user where id % 2 = 1;db.user.find(&#123;"_id":&#123;"$mod":[2,1]&#125;&#125;)//上一条取反db.user.find(&#123; "_id":&#123;"$not":&#123;"$mod":[2,1]&#125;&#125;&#125;)/** *4、成员查询 * $in ， $nin */// select * from user where age in (1,2,3);db.user.find(&#123;"age":&#123;"$in":[1,2,3]&#125;&#125;)// select * from user where name not in ("zhangsan","lisi");db.user.find(&#123;"name":&#123;"$nin":["zhangsan","lisi"]&#125;&#125;)/** *5、$type操作符查询 * MongoDB可以使用的类型操作符：1-Double、2-String、3-Object、4-Array、5-Binary Data、8-Boolan、9-Date ... */// 查询name是字符串类型的数据db.user.find(&#123;name:&#123;$type:2&#125;&#125;)/** *6、正则查询 * 正则定义在/ /内 */ // select * from user where name regexp '^z.*?(u|i)$';// 匹配规则：z开头、n或u结尾，不区分大小写db.user.find(&#123;'name':/^z.*?(n|u)$/i&#125;)/** *7、投影查询 * 1用来显示字段而0是用来隐藏字段，_id会默认显示出来。 */// select name,age from user where id=3;db.user.find(&#123;'_id':3&#125;,&#123;'_id':0,'name':1,'age':1&#125;)// select name,age from user where name regexp "^z.*(n|u)$";db.user.find(&#123; "name":/^z.*(n|u)$/i&#125;,&#123; "_id":0, "name":1, "age":1&#125;)/** *8、数组查询 * 查询数组相关 */// 查hobbies中有dancing的人db.user.find(&#123; "hobbies":"music"&#125;)// 查看既有dancing爱好又有tea爱好的人db.user.find(&#123; "hobbies":&#123;"$all":["music","read"]&#125;&#125;)// 查看索引第2个爱好为dancing的人db.user.find(&#123; "hobbies.2":"read"&#125;)// 查看所有人的第1个到第3个爱好，第一个&#123;&#125;表示查询条件为所有，第二个是显示条件db.user.find(&#123;&#125;,&#123; "_id":0, "name":0, "age":0, "addr":0, "hobbies":&#123;"$slice":[0,2]&#125;,&#125;)// 查看所有人最后两个爱好，第一个&#123;&#125;表示查询条件为所有，第二个是显示条件db.user.find(&#123;&#125;,&#123; "_id":0, "name":0, "age":0, "addr":0, "hobbies":&#123;"$slice":-2&#125;,&#125;)// 查询子文档有"country":"China"的人db.user.find(&#123; "addr.country":"China"&#125;)/** *9、排序查询 * 1 为升序排列，而-1是用于降序排列 */// 按姓名正序db.user.find().sort(&#123;"name":1&#125;)// 按年龄倒序 按id正序db.user.find().sort(&#123;"age":-1,'_id':1&#125;)/** *10、分页查询 * limit表示取多少个document，skip代表跳过几个document * 分页公式：db.user.find().skip((pageNum–1)*pageSize).limit(pageSize) */db.user.find().limit(2).skip(0) // 前两个db.user.find().limit(2).skip(2) // 第三个和第四个db.user.find().limit(2).skip(4) // 第五个和第六个/** *11、统计查询 */// 查询_id大于3的人数// 方式一db.user.count(&#123;'_id':&#123;"$gt":3&#125;&#125;) // 方式二db.user.find(&#123;_id:&#123;"$gt":3&#125;&#125;).count()/** *11、聚合查询 * 在MongoDB中聚合为aggregate，聚合函数主要用到$match $group $avg $project $concat，可以加"$match"也可以不加$match */// 练习Aggregate语法，先插入如下数据：emp1 = &#123;"_id":1,"name":"武大郎","sex":"male","age":18,"hire_date":"20170301","post":"烧饼检察官","salary":7300.33&#125;emp2 = &#123;"_id":2,"name":"武松","sex":"male","age":78,"hire_date":"20150302","post":"公务员","salary":71000000.31&#125;emp3 = &#123;"_id":3,"name":"宋江","sex":"male","age":81,"hire_date":"20130305","post":"公务员","salary":78300&#125;emp4 = &#123;"_id":4,"name":"林冲","sex":"male","age":73,"hire_date":"20140701","post":"公务员","salary":73500&#125;emp5 = &#123;"_id":5,"name":"林冲","sex":"male","age":73,"hire_date":"20140701","post":"公务员","salary":73500&#125;emp6 = &#123;"_id":6,"name":"柴进","sex":"male","age":28,"hire_date":"20121101","post":"公务员","salary":72100&#125;emp7 = &#123;"_id":7,"name":"卢俊义","sex":"female","age":18,"hire_date":"20110211","post":"公务员","salary":79000&#125;emp8 = &#123;"_id":8,"name":"高俅","sex":"male","age":18,"hire_date":"19000301","post":"公务员","salary":730000&#125;emp9 = &#123;"_id":9,"name":"鲁智深","sex":"male","age":48,"hire_date":"20101111","post":"公务员","salary":710000&#125;emp10 = &#123;"_id":10,"name":"史进","sex":"female","age":48,"hire_date":"20150311","post":"打手","salary":73000.13&#125;emp11 = &#123;"_id":11,"name":"李逵","sex":"female","age":38,"hire_date":"20101101","post":"打手","salary":72000.35&#125;emp12 = &#123;"_id":12,"name":"周通","sex":"female","age":18,"hire_date":"20110312","post":"打手","salary":71000.37&#125;emp13 = &#123;"_id":13,"name":"石秀","sex":"female","age":18,"hire_date":"20160513","post":"打手","salary":73000.29&#125;emp14 = &#123;"_id":14,"name":"李忠","sex":"female","age":28,"hire_date":"20170127","post":"打手","salary":74000.33&#125;emp15 = &#123;"_id":15,"name":"吴用","sex":"male","age":28,"hire_date":"20160311","post":"文人","salary":710000.13&#125;emp16 = &#123;"_id":16,"name":"萧让","sex":"male","age":18,"hire_date":"19970312","post":"文人","salary":720000&#125;emp17 = &#123;"_id":17,"name":"安道全","sex":"female","age":18,"hire_date":"20130311","post":"文人","salary":719000&#125;emp18 = &#123;"_id":18,"name":"公孙胜","sex":"male","age":18,"hire_date":"20150411","post":"文人","salary":718000&#125;emp19 = &#123;"_id":19,"name":"朱贵","sex":"female","age":18,"hire_date":"20140512","post":"文人","salary":717000&#125;db.emp.insertMany([emp1, emp2, emp3, emp4, emp5, emp6, emp7, emp8, emp9, emp10, emp11, emp12, emp13, emp14, emp15, emp16, emp17, emp18, emp19])/** *$match和$group **/// &#123;"$match":&#123;"字段":"条件"&#125;&#125;,可以使用任何常用查询操作符$gt,$lt,$in等// select * from db1.emp where post='公务员';db.emp.aggregate([&#123;"$match":&#123;"post":"公务员"&#125;&#125;])// select * from db1.emp where id &gt; 3 group by post; db.emp.aggregate([ &#123;"$match":&#123;"_id":&#123;"$gt":3&#125;&#125;&#125;, &#123;"$group":&#123;"_id":"$post",'avg_salary':&#123;"$avg":"$salary"&#125;&#125;&#125;])// select * from db1.emp where id &gt; 3 group by post having avg(salary) &gt; 10000; db.emp.aggregate([ &#123;"$match":&#123;"_id":&#123;"$gt":3&#125;&#125;&#125;, &#123;"$group":&#123;"_id":"$post",'avg_salary':&#123;"$avg":"$salary"&#125;&#125;&#125;, &#123;"$match":&#123;"avg_salary":&#123;"$gt":10000&#125;&#125;&#125;])// &#123;"$group":&#123;"_id":分组字段,"新的字段名":聚合操作符&#125;&#125;// 将分组字段传给$group函数的_id字段即可//&#123;"$group":&#123;"_id":"$sex"&#125;&#125; #按照性别分组//&#123;"$group":&#123;"_id":"$post"&#125;&#125; #按照职位分组//&#123;"$group":&#123;"_id":&#123;"state":"$state","city":"$city"&#125;&#125;&#125; #按照多个字段分组，比如按照州市分组// 分组后聚合得结果,类似于sql中聚合函数的聚合操作符：$sum、$avg、$max、$min、$first、$last//例1：select post,max(salary) from db1.emp group by post; db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","max_salary":&#123;"$max":"$salary"&#125;&#125;&#125;])//例2：取每个部门最大薪资与最低薪资db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","max_salary":&#123;"$max":"$salary"&#125;,"min_salary":&#123;"$min":"$salary"&#125;&#125;&#125;])//例3：如果字段是排序后的，那么$first,$last会很有用,比用$max和$min效率高db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","first_id":&#123;"$first":"$_id"&#125;&#125;&#125;])//4：求每个部门的总工资db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","count":&#123;"$sum":"$salary"&#125;&#125;&#125;, &#123;"$sort": &#123;"count": 1&#125;&#125;])//5：求每个部门的人数db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","count":&#123;"$sum":1&#125;&#125;&#125;, &#123;"$sort": &#123;"count": 1&#125;&#125;])// 数组操作符// &#123;"$addToSet":expr&#125;#不重复// &#123;"$push":expr&#125;#重复// 查询岗位名以及各岗位内的员工姓名:select post,group_concat(name) from db1.emp group by post;// 重复的也查询出来db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","names":&#123;"$push":"$name"&#125;&#125;&#125;])// 查询结果/* 1 */&#123; "_id" : "文人", "names" : [ "吴用", "萧让", "安道全", "公孙胜", "朱贵" ]&#125;/* 2 */&#123; "_id" : "打手", "names" : [ "史进", "李逵", "周通", "石秀", "李忠" ]&#125;/* 3 */&#123; "_id" : "公务员", "names" : [ "武松", "宋江", "林冲", "林冲", "柴进", "卢俊义", "高俅", "鲁智深" ]&#125;/* 4 */&#123; "_id" : "烧饼检察官", "names" : [ "武大郎" ]&#125;// 查询不重复的，如果有重复的保留一个db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","names":&#123;"$addToSet":"$name"&#125;&#125;&#125;])// 查询结果/* 1 */&#123; "_id" : "文人", "names" : [ "吴用", "朱贵", "萧让", "安道全", "公孙胜" ]&#125;/* 2 */&#123; "_id" : "打手", "names" : [ "李忠", "史进", "李逵", "周通", "石秀" ]&#125;/* 3 */&#123; "_id" : "公务员", "names" : [ "鲁智深", "高俅", "宋江", "林冲", "卢俊义", "武松", "柴进" ]&#125;/* 4 */&#123; "_id" : "烧饼检察官", "names" : [ "武大郎" ]&#125;/** * $project **///&#123;"$project":&#123;"要保留的字段名":1,"要去掉的字段名":0,"新增的字段名":"表达式"&#125;&#125;// select name,post,(age+1) as new_age from db1.emp;db.emp.aggregate([ &#123; $project:&#123; "name":1, "post":1, "new_age":&#123;"$add":["$age",1]&#125; &#125; &#125;])/** * $sort和$limit和$skip **/// 排序：&#123;"$sort":&#123;"字段名":1,"字段名":-1&#125;&#125; #1升序，-1降序// 限制：&#123;"$limit":n&#125; // 跳过：&#123;"$skip":n&#125; #跳过多少个文档 // 取平均工资最高的前两个部门db.emp.aggregate([&#123; "$group":&#123;"_id":"$post","平均工资":&#123;"$avg":"$salary"&#125;&#125;&#125;,&#123; "$sort":&#123;"平均工资":-1&#125;&#125;,&#123; "$limit":2&#125;])// 取平均工资最高的第二个部门db.emp.aggregate([&#123; "$group":&#123;"_id":"$post","平均工资":&#123;"$avg":"$salary"&#125;&#125;&#125;,&#123; "$sort":&#123;"平均工资":-1&#125;&#125;,&#123; "$limit":2&#125;,&#123; "$skip":1&#125;])/** * $sample **/// 随机获取3个文档db.emp.aggregate([ &#123;$sample: &#123;size:3&#125;&#125;])/** * $concat和$substr和$toLower和$toUpper **/ // 截取字符串db.emp.aggregate([ &#123; $project:&#123; "_id":0, "str": &#123;$substr: ["$sex", 0, 2]&#125; &#125; &#125;])// 拼接db.emp.aggregate([ &#123; $project:&#123; "name":1, "post":1, "name_sex": &#123;$concat: ["$name", "测试拼接", "$sex"]&#125; &#125; &#125;])// 将性别的英文转为大写db.emp.aggregate([&#123;"$project":&#123;"sex":&#123;"$toUpper":"$sex"&#125;&#125;&#125;])/** *12、索引 * 索引通常能够极大的提高查询的效率，MongoDB使用 ensureIndex()方法来创建索引 */db.COLLECTION_NAME.ensureIndex(&#123;KEY:1&#125;)// 语法中 Key 值为你要创建的索引字段，1为指定按升序创建索引，-1则为按降序来创建索引。db.user.ensureIndex(&#123;"name":-1&#125;)// 我们可以指定所建立索引的名字，如下所示：db.user.ensureIndex(&#123;"name":1&#125;,&#123;"name":"nameIndex"&#125;)//查询索引的语法格式如下所示：db.COLLECTION_NAME.getIndexes()db.user.getIndexes()//删除索引的语法格式如下所示：db.COLLECTION_NAME.dropIndex(INDEX_NAME)db.user.dropIndex("nameIndex")]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java操作MongoDB数据库CRUD（增删查改）]]></title>
    <url>%2F2016%2F01%2F25%2Fmd_%E6%95%B0%E6%8D%AE%E5%BA%93%2FJava%E6%93%8D%E4%BD%9CMongoDB%E6%95%B0%E6%8D%AE%E5%BA%93CRUD%EF%BC%88%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9%EF%BC%89%2F</url>
    <content type="text"><![CDATA[借助mongo-java-driver包，对MongoDB数据库的集合（DataTable）及文档（BSON对象数据）进行增删查改操作。本文的核心在于查询操作，善用mongo-java-driver包下的Iterable迭代器、fing()方法、aggregate()方法，理解Document对象映射BSON对象的底层实现，可完成类似窗口命令行下javascript代码操作MongoDB数据库的所有查询。 1. 环境搭建1.1 创建项目本文是在Idea编辑器Maven环境下创建quickstart项目。 1.2 添加依赖引入junit测试单元，可方便测试代码；引入MongoDB驱动包，3.9.1版本； 123456789101112&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; &lt;!--MongoDB--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 2. 测试环境搭建2.1 封装MongoDBUtil工具类此步骤略过，该工具类需具备连接池参数信息的配置，获取MongClient对象及关闭mongoClient功能。 2.2 准备junit测试代码，并测试连接123456789101112131415161718192021ongoClient mongoClient = null;@Beforepublic void testInit() &#123; // 获取连接 mongoClient = MongoDBUtil.getMongoClient();&#125;@Afterpublic void testClose() &#123; MongoDBUtil.close(mongoClient);&#125;@Testpublic void testDB() &#123; // 连接数据库，存在选中，不存在创建 MongoDatabase db = mongoClient.getDatabase("myDB"); // 删除数据库 mongoClient.dropDatabase("myDB");&#125; 3. 数据库CRUD（增删查改）操作3.1 创建集合集合既是关系型数据库的表。1234567891011121314151617181920212223242526@Test public void testCreate()&#123; //1.’连接数据库，若存在即选中，若不存在就建立 MongoDatabase mongoDatabase = mongoClient.getDatabase("javadb"); //创建集合，此步骤若创建已存在集合，将会报错 //mongoDatabase.createCollection("javaTset"); //2.获取集合，若存在即选中，若不存在就建立 MongoCollection mongoCollection = mongoDatabase.getCollection("javaTset"); //3.获取集合中文档个数 Long collectionSize = mongoCollection.countDocuments(); System.out.println("javadb集合中文档个数："+collectionSize); //3.获取整个数据库下集合名称列表 MongoIterable&lt;String&gt; mongoIterable = mongoDatabase.listCollectionNames(); //4.获取迭代器,并遍历 MongoCursor&lt;String&gt; mongoCursor = mongoIterable.iterator(); while(mongoCursor.hasNext())&#123; System.out.println(mongoCursor.next()); &#125; mongoCursor.close(); //5.删除当前集合 mongoCollection.drop(); &#125; 结果： 1234javadb集合中文档个数：5empjavadbuser 3.2 创建文档文档既是关系型数据库的row，java代码中由Document（键值对形式，键为字符串，值可以为字符串、数字、Document对象）对象体现，很好的对应了MongoDB中的Bson对象。12345678910111213141516171819202122232425262728293031323334353637 @Test public void testCrud01()&#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection collection = database.getCollection("javaTest"); //插入一条文档 Document document = new Document(); document.put("name","zhangsan123"); document.put("age",11); document.put("addr","shanghai"); document.put("date",new Date()); collection.insertOne(document);//插入多条文档 Document document1 = new Document(); document1.put("name","lisi"); document1.put("age",11); document1.put("addr","beijing"); document1.put("date",new Date()); Document document2 = new Document(); document2.put("name","wangwu"); document2.put("age",55); document2.put("addr","guangzhou"); document2.put("date",new Date()); List&lt;Document&gt; list = new ArrayList&lt;&gt;(); list.add(document1); list.add(document2); collection.insertMany(list); //查询所有文档，获取迭代器和游标，并遍历 MongoCursor&lt;Document&gt; cursor = collection.find().iterator(); while (cursor.hasNext())&#123; System.out.println(cursor.next().toString()); &#125; cursor.close(); &#125; 结果： 123Document&#123;&#123;_id=5c024316b4d5c01d14924040, name=zhangsan123, age=11, addr=shanghai, date=Sat Dec 01 16:15:18 CST 2018&#125;&#125;Document&#123;&#123;_id=5c024317b4d5c01d14924041, name=lisi, age=11, addr=beijing, date=Sat Dec 01 16:15:19 CST 2018&#125;&#125;Document&#123;&#123;_id=5c024317b4d5c01d14924042, name=wangwu, age=55, addr=guangzhou, date=Sat Dec 01 16:15:19 CST 2018&#125;&#125; 3.3 更新文档123456789101112131415161718192021@Testpublic void testCrud03()&#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection collection = database.getCollection("javaTest"); /** * 更新操作 */ //1.获取到要更新的文档 BasicDBObject old = new BasicDBObject(); old.put("name","lisi"); //2.创建更新的文档(需要跟新的字段和值) BasicDBObject newObj = new BasicDBObject(); newObj.put("age",22); //3.创建更新操作 BasicDBObject update = new BasicDBObject("$set",newObj); //4.执行更新 collection.updateOne(old,update);//更新匹配的第一条数据 //collection.updateMany(old,update);//更新多条数据&#125; 3.4 删除文档12345678910111213@Testpublic void testCrud04() &#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection collection = database.getCollection("javaTest"); /** * 删除文档 */ BasicDBObject obj = new BasicDBObject(); obj.put("name","wangwu"); collection.deleteOne(obj);&#125; 3.5 查询文档查询之前需要在MongoDB数据库中新建两个查询源：user、emp，初始化JavaScript代码如下：1234567//user表user1 = &#123; "_id":1, "name":"zhangsan","age":1, "hobbies":["music", "read"],"addr":&#123; "country":"China","city":"BJ" &#125;&#125;user2 = &#123; "_id":2,"name":"lisi","age":2, "hobbies":["music", "read"],"addr":&#123;"country":"China", "city":"SH"&#125;&#125;user3 = &#123; "_id":3, "name":"wangwu","age":3,"hobbies":["music", "read"],"addr":&#123;"country":"China","city":"GZ"&#125;&#125;user4 = &#123;"_id":4,"name":"zhaoliu","age":4,"hobbies":["music", "read"],"addr":&#123; "country":"China","city":"SZ"&#125;&#125;user5 = &#123;"_id":5,"name":"tianqi","age":5,"hobbies":["music", "read"],"addr":&#123;"country":"China","city":"TY"&#125;&#125;db.user.insertMany([user1, user2, user3, user4, user5]) 12345678910111213141516171819202122// emp表，练习Aggregate语法，先插入如下数据：emp1 = &#123;"_id":1,"name":"武大郎","sex":"male","age":18,"hire_date":"20170301","post":"烧饼检察官","salary":7300.33&#125;emp2 = &#123;"_id":2,"name":"武松","sex":"male","age":78,"hire_date":"20150302","post":"公务员","salary":71000000.31&#125;emp3 = &#123;"_id":3,"name":"宋江","sex":"male","age":81,"hire_date":"20130305","post":"公务员","salary":78300&#125;emp4 = &#123;"_id":4,"name":"林冲","sex":"male","age":73,"hire_date":"20140701","post":"公务员","salary":73500&#125;emp5 = &#123;"_id":5,"name":"林冲","sex":"male","age":73,"hire_date":"20140701","post":"公务员","salary":73500&#125;emp6 = &#123;"_id":6,"name":"柴进","sex":"male","age":28,"hire_date":"20121101","post":"公务员","salary":72100&#125;emp7 = &#123;"_id":7,"name":"卢俊义","sex":"female","age":18,"hire_date":"20110211","post":"公务员","salary":79000&#125;emp8 = &#123;"_id":8,"name":"高俅","sex":"male","age":18,"hire_date":"19000301","post":"公务员","salary":730000&#125;emp9 = &#123;"_id":9,"name":"鲁智深","sex":"male","age":48,"hire_date":"20101111","post":"公务员","salary":710000&#125;emp10 = &#123;"_id":10,"name":"史进","sex":"female","age":48,"hire_date":"20150311","post":"打手","salary":73000.13&#125;emp11 = &#123;"_id":11,"name":"李逵","sex":"female","age":38,"hire_date":"20101101","post":"打手","salary":72000.35&#125;emp12 = &#123;"_id":12,"name":"周通","sex":"female","age":18,"hire_date":"20110312","post":"打手","salary":71000.37&#125;emp13 = &#123;"_id":13,"name":"石秀","sex":"female","age":18,"hire_date":"20160513","post":"打手","salary":73000.29&#125;emp14 = &#123;"_id":14,"name":"李忠","sex":"female","age":28,"hire_date":"20170127","post":"打手","salary":74000.33&#125;emp15 = &#123;"_id":15,"name":"吴用","sex":"male","age":28,"hire_date":"20160311","post":"文人","salary":710000.13&#125;emp16 = &#123;"_id":16,"name":"萧让","sex":"male","age":18,"hire_date":"19970312","post":"文人","salary":720000&#125;emp17 = &#123;"_id":17,"name":"安道全","sex":"female","age":18,"hire_date":"20130311","post":"文人","salary":719000&#125;emp18 = &#123;"_id":18,"name":"公孙胜","sex":"male","age":18,"hire_date":"20150411","post":"文人","salary":718000&#125;emp19 = &#123;"_id":19,"name":"朱贵","sex":"female","age":18,"hire_date":"20140512","post":"文人","salary":717000&#125;db.emp.insertMany([emp1, emp2, emp3, emp4, emp5, emp6, emp7, emp8, emp9, emp10, emp11, emp12, emp13, emp14, emp15, emp16, emp17, emp18, emp19]) 条件查询1:匹配查询123456789101112131415161718@Testpublic void testCrud01()&#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection collection = database.getCollection("user"); /** * 条件查询1 * 单一字段匹配查询 */ BasicDBObject obj = new BasicDBObject(); obj.put("name","lisi"); MongoCursor&lt;Document&gt; docs = collection.find(obj).iterator(); while (docs.hasNext())&#123; System.out.println(docs.next().toString()); &#125; docs.close();&#125; 结果： 1Document&#123;&#123;_id=6.0, name=lisi, age=42.0, hobbies=[music, read], addr=Document&#123;&#123;country=China, city=SH&#125;&#125;&#125;&#125; 条件查询2:比较、逻辑、投影、排序等查询1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192@Testpublic void testCrud02()&#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection&lt;Document&gt; collection = database.getCollection("user"); /** * 条件查询2 */ System.out.println("查询条件_id==6.0 **************************************"); FindIterable&lt;Document&gt; iterable = collection.find(new Document("_id",6.0)); iterable.forEach(new Block&lt;Document&gt;() &#123; @Override public void apply(Document document) &#123; System.out.println(document.toJson()); &#125; &#125;); System.out.println("查询条件name == wangwu **************************************"); FindIterable&lt;Document&gt; iterable2 = collection.find( new Document("name",new Document("$eq","wangwu"))); for (Document doc :iterable2)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件name != wangwu **************************************"); FindIterable&lt;Document&gt; iterable3 = collection.find( new Document("name",new Document("$ne","wangwu"))); for (Document doc :iterable3)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件_id &gt;= 4 **************************************"); FindIterable&lt;Document&gt; iterable4 = collection.find( new Document("_id",new Document("$gte",4))); for (Document doc :iterable4)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件_id &lt;= 4 **************************************"); FindIterable&lt;Document&gt; iterable5 = collection.find( new Document("_id",new Document("$lte",4))); for (Document doc :iterable5)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件_id &lt;=4 &amp;&amp; age&gt;60 **************************************"); FindIterable&lt;Document&gt; iterable6 = collection.find( Filters.and(Filters.lte("_id",4),Filters.gt("age",60))); for (Document doc :iterable6)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件_id &lt;=4 || age&gt;60 **************************************"); FindIterable&lt;Document&gt; iterable7 = collection.find( Filters.or(Filters.lte("_id",4),Filters.gt("age",60))); for (Document doc :iterable7)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件_id in 1,3,5 **************************************"); FindIterable&lt;Document&gt; iterable8 = collection.find( Filters.in("_id",1,3,5)); for (Document doc :iterable8)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件sort 按年龄排序（升序） **************************************"); FindIterable&lt;Document&gt; iterable9 = collection.find() .sort(new Document("age",1)); for (Document doc :iterable9)&#123; System.out.println(doc.toJson()); &#125; System.out.println("查询条件 分页 第二页 每页三条 **************************************"); FindIterable&lt;Document&gt; iterable10 = collection.find() .limit(3).skip(3); for (Document doc :iterable10)&#123; System.out.println(doc.toJson()); &#125; /** * select name,age from user where id=3; * db.user.find(&#123;'_id':3&#125;,&#123;'_id':0,'name':1,'age':1&#125;) */ System.out.println("查询条件 投影查询 **************************************"); Document document11_1 = new Document(); document11_1.put("_id",3); Document document11_2 = new Document(); document11_2.put("_id",0); document11_2.put("name",1); document11_2.put("age",1); BasicDBObject object = new BasicDBObject(); Document document11 = new Document(); FindIterable&lt;Document&gt; iterable11 = collection.find(document11_1) .projection(document11_2);//projection方法查询指定字段 for (Document doc :iterable11)&#123; System.out.println(doc.toJson()); &#125;&#125; 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859查询条件_id==6.0 **************************************&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 42.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SH&quot; &#125; &#125;查询条件name==wangwu **************************************&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 7.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;查询条件name!=wangwu **************************************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : &#123; &quot;$oid&quot; : &quot;5c00e7520af8c80c1ed52c77&quot; &#125;, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0 &#125;&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 42.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SH&quot; &#125; &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 9.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 8.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;李四&quot;, &quot;age&quot; : 60.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;查询条件_id &gt;=4 **************************************&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 42.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SH&quot; &#125; &#125;&#123; &quot;_id&quot; : 7.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 8.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 9.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;查询条件_id &lt;=4 **************************************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;李四&quot;, &quot;age&quot; : 60.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;查询条件_id &lt;=4&amp;&amp;age&gt;60 **************************************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;查询条件_id &lt;=4||age&gt;60 **************************************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;李四&quot;, &quot;age&quot; : 60.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : &#123; &quot;$oid&quot; : &quot;5c00e7520af8c80c1ed52c77&quot; &#125;, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0 &#125;查询条件_id in 1,3,5 **************************************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;查询条件sort 按年龄排序（升序） **************************************&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 42.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SH&quot; &#125; &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 7.0, &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;GZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 8.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 9.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;李四&quot;, &quot;age&quot; : 60.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;&#123; &quot;_id&quot; : &#123; &quot;$oid&quot; : &quot;5c00e7520af8c80c1ed52c77&quot; &#125;, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0 &#125;&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 180.0 &#125;查询条件 分页 第二页 每页三条 **************************************&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 44.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;SZ&quot; &#125; &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;tianqi&quot;, &quot;age&quot; : 45.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;TY&quot; &#125; &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;aaa&quot;, &quot;age&quot; : 140.0, &quot;hobbies&quot; : [&quot;music&quot;, &quot;read&quot;], &quot;addr&quot; : &#123; &quot;country&quot; : &quot;China&quot;, &quot;city&quot; : &quot;BJ&quot; &#125; &#125;查询条件 投影查询 **************************************&#123; &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 43.0 &#125; 条件查询3:聚合查询\$match和\$group和\$project12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Testpublic void testCrud06() &#123; /** * 条件查询3 */ //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection&lt;Document&gt; collection = database.getCollection("emp"); /** * 使用$match和$group * select * from db1.emp where post='公务员'; * db.emp.aggregate([&#123;"$match":&#123;"post":"公务员"&#125;&#125;]) */ System.out.println("select * from db1.emp where post='公务员'*********************"); Document match = new Document("post","公务员"); Document doc1 = new Document("$match",match); List&lt;Document&gt; list = new ArrayList&lt;&gt;(); list.add(doc1); AggregateIterable&lt;Document&gt; iterable01 = collection.aggregate(list); for (Document doc :iterable01)&#123; System.out.println(doc.toJson()); &#125; /** * select * from db1.emp where id &gt; 3 group by post; * db.emp.aggregate([ * &#123;"$match":&#123;"_id":&#123;"$gt":3&#125;&#125;&#125;, * &#123;"$group":&#123;"_id":"$post",'avg_salary':&#123;"$avg":"$salary"&#125;&#125;&#125; * ]) */ System.out.println("select * from db1.emp where id &gt; 3 group by post*******************"); Document document2 = new Document(); document2.put("_id","$post"); document2.put("avg_salary",new Document("$avg","$salary")); AggregateIterable&lt;Document&gt; iterable02 = collection.aggregate( new ArrayList&lt;Document&gt;(Arrays.asList( new Document("$match",new Document("_id",new Document("$gt",3))), new Document("$group",document2) )) ); for (Document doc :iterable02)&#123; System.out.println(doc.toJson()); &#125; /** * select post,max(salary) from db1.emp group by post; * db.emp.aggregate([&#123;"$group":&#123;"_id":"$post","max_salary":&#123;"$max":"$salary"&#125;&#125;&#125;]) */ System.out.println("select post,max(salary) from db1.emp group by post****************"); Document document3 = new Document(); document3.put("_id","$post"); document3.put("max_salary",new Document("$max","$salary")); AggregateIterable&lt;Document&gt; iterable03 = collection.aggregate( new ArrayList&lt;Document&gt;(Arrays.asList( new Document("$group",document3) )) ); for (Document doc :iterable03)&#123; System.out.println(doc.toJson()); &#125; System.out.println("# select name,post,(age+1) as new_age from db1.emp;******************"); Document document4 = new Document(); document4.put("name",1); document4.put("post",1); document4.put("new_age",new Document("$add",new ArrayList&lt;&gt;(Arrays.asList("$age",1)))); AggregateIterable&lt;Document&gt; iterable04 = collection.aggregate( new ArrayList&lt;Document&gt;(Arrays.asList( new Document("$project",document4) )) ); for (Document doc :iterable04)&#123; System.out.println(doc.toJson()); &#125;&#125; 结果： 1234567891011121314151617181920212223242526272829303132333435363738select * from db1.emp where post=&apos;公务员&apos;*********************&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;武松&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 78.0, &quot;hire_date&quot; : &quot;20150302&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 7.100000031E7 &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;宋江&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 81.0, &quot;hire_date&quot; : &quot;20130305&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 78300.0 &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;林冲&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 73.0, &quot;hire_date&quot; : &quot;20140701&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 73500.0 &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;林冲&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 73.0, &quot;hire_date&quot; : &quot;20140701&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 73500.0 &#125;&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;柴进&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 28.0, &quot;hire_date&quot; : &quot;20121101&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 72100.0 &#125;&#123; &quot;_id&quot; : 7.0, &quot;name&quot; : &quot;卢俊义&quot;, &quot;sex&quot; : &quot;female&quot;, &quot;age&quot; : 18.0, &quot;hire_date&quot; : &quot;20110211&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 79000.0 &#125;&#123; &quot;_id&quot; : 8.0, &quot;name&quot; : &quot;高俅&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 18.0, &quot;hire_date&quot; : &quot;19000301&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 730000.0 &#125;&#123; &quot;_id&quot; : 9.0, &quot;name&quot; : &quot;鲁智深&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 48.0, &quot;hire_date&quot; : &quot;20101111&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;salary&quot; : 710000.0 &#125;select * from db1.emp where id &gt; 3 group by post*******************&#123; &quot;_id&quot; : &quot;文人&quot;, &quot;avg_salary&quot; : 716800.026 &#125;&#123; &quot;_id&quot; : &quot;打手&quot;, &quot;avg_salary&quot; : 72600.294 &#125;&#123; &quot;_id&quot; : &quot;公务员&quot;, &quot;avg_salary&quot; : 289683.3333333333 &#125;select post,max(salary) from db1.emp group by post****************&#123; &quot;_id&quot; : &quot;文人&quot;, &quot;max_salary&quot; : 720000.0 &#125;&#123; &quot;_id&quot; : &quot;打手&quot;, &quot;max_salary&quot; : 74000.33 &#125;&#123; &quot;_id&quot; : &quot;公务员&quot;, &quot;max_salary&quot; : 7.100000031E7 &#125;&#123; &quot;_id&quot; : &quot;烧饼检察官&quot;, &quot;max_salary&quot; : 7300.33 &#125;# select name,post,(age+1) as new_age from db1.emp;******************&#123; &quot;_id&quot; : 1.0, &quot;name&quot; : &quot;武大郎&quot;, &quot;post&quot; : &quot;烧饼检察官&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 2.0, &quot;name&quot; : &quot;武松&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 79.0 &#125;&#123; &quot;_id&quot; : 3.0, &quot;name&quot; : &quot;宋江&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 82.0 &#125;&#123; &quot;_id&quot; : 4.0, &quot;name&quot; : &quot;林冲&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 74.0 &#125;&#123; &quot;_id&quot; : 5.0, &quot;name&quot; : &quot;林冲&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 74.0 &#125;&#123; &quot;_id&quot; : 6.0, &quot;name&quot; : &quot;柴进&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 29.0 &#125;&#123; &quot;_id&quot; : 7.0, &quot;name&quot; : &quot;卢俊义&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 8.0, &quot;name&quot; : &quot;高俅&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 9.0, &quot;name&quot; : &quot;鲁智深&quot;, &quot;post&quot; : &quot;公务员&quot;, &quot;new_age&quot; : 49.0 &#125;&#123; &quot;_id&quot; : 10.0, &quot;name&quot; : &quot;史进&quot;, &quot;post&quot; : &quot;打手&quot;, &quot;new_age&quot; : 49.0 &#125;&#123; &quot;_id&quot; : 11.0, &quot;name&quot; : &quot;李逵&quot;, &quot;post&quot; : &quot;打手&quot;, &quot;new_age&quot; : 39.0 &#125;&#123; &quot;_id&quot; : 12.0, &quot;name&quot; : &quot;周通&quot;, &quot;post&quot; : &quot;打手&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 13.0, &quot;name&quot; : &quot;石秀&quot;, &quot;post&quot; : &quot;打手&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 14.0, &quot;name&quot; : &quot;李忠&quot;, &quot;post&quot; : &quot;打手&quot;, &quot;new_age&quot; : 29.0 &#125;&#123; &quot;_id&quot; : 15.0, &quot;name&quot; : &quot;吴用&quot;, &quot;post&quot; : &quot;文人&quot;, &quot;new_age&quot; : 29.0 &#125;&#123; &quot;_id&quot; : 16.0, &quot;name&quot; : &quot;萧让&quot;, &quot;post&quot; : &quot;文人&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 17.0, &quot;name&quot; : &quot;安道全&quot;, &quot;post&quot; : &quot;文人&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 18.0, &quot;name&quot; : &quot;公孙胜&quot;, &quot;post&quot; : &quot;文人&quot;, &quot;new_age&quot; : 19.0 &#125;&#123; &quot;_id&quot; : 19.0, &quot;name&quot; : &quot;朱贵&quot;, &quot;post&quot; : &quot;文人&quot;, &quot;new_age&quot; : 19.0 &#125; 条件查询4:\$sort和\$limit和\$skip1234567891011121314151617181920212223242526@Testpublic void testCrud04() &#123; //连接数据库，存在选中，不存在就建立 MongoDatabase database = mongoClient.getDatabase("javadb"); //获取集合 MongoCollection&lt;Document&gt; collection = database.getCollection("emp"); /** * 条件查询4 */ System.out.println("取平均工资最高的第二个部门***************************"); Document group = new Document(); group.put("_id","$post"); group.put("平均工资",new Document("$avg","$salary")); AggregateIterable&lt;Document&gt; iterable05 = collection.aggregate( new ArrayList&lt;Document&gt;(Arrays.asList( new Document("$group",group), new Document("$sort",new Document("平均工资",-1)), new Document("$limit",2), new Document("$skip",1) )) ); for (Document doc :iterable05)&#123; System.out.println(doc.toJson()); &#125; &#125; 12取平均工资最高的第二个部门***************************&#123; &quot;_id&quot; : &quot;文人&quot;, &quot;平均工资&quot; : 716800.026 &#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Linux启动MongoDB所遇问题]]></title>
    <url>%2F2016%2F01%2F25%2Fmd_%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%B5%85%E8%B0%88Linux%E5%90%AF%E5%8A%A8MongoDB%E6%89%80%E9%81%87%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[libc.so.6: version `GLIBC_2.14’ not found问题 出现这个错误的原因是：Red Hat系统的glibc的版本太低，软件编译时使用了较高的glibc版本引起的。解决方法如下： 1.查看系统glibc支持的版本命令行输入strings /lib64/libc.so.6 |grep GLIBC_[root@localhost bin]# strings /lib64/libc.so.6 |grep GLIBC_GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE命令行输入rpm -qa |grep glibc[root@localhost bin]# rpm -qa |grep glibcglibc-headers-2.12-1.212.el6.x86_64glibc-2.12-1.212.el6.x86_64glibc-devel-2.12-1.212.el6.x86_64glibc-common-2.12-1.212.el6.x86_64可以看出系统只支持到2.12版本，本文使用的是glibc-2.14.tar.xz这个版本。2.下载glibc-2.14.tar.xz注：可以到http://www.gnu.org/software/libc/下载最新版本，我这里直接通过wget命令下载glibc-2.14.tar.xz&nbsp;这个版本，解压到任意目录准备编译命令行输入wget&nbsp;http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.xz[root@localhost usr]# wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.xz3.解压到指定文件夹命令行输入[root@localhost usr]# tar xvJf glibc-2.14.tar.xz glibc[root@localhost usr]# tar xvJf glibc-2.14.tar.xz /usr/glibc注：若解压tar.xz文件出错，请命令行输入安装：yum -y install xz4.进入到glibc源码目录并建立build目录，并进入[root@localhost usr]# cd glibc[root@localhost glibc]# cd glibc-2.14[root@localhost build]# mkdir build[root@localhost glibc-2.14]# cd build[root@localhost build]#5.运行configure配置，make &amp;&amp; sudo &nbsp;make install[root@localhost build]# ../configure –prefix=/opt/glibc-2.14[root@localhost build]# make -j4持续5-10分钟的等待。。。[root@localhost glibc-2.14]# make install持续2-5分钟的等待。。。6.配置（重要步骤，缺少文件）[root@localhost glibc-2.14]# cp /etc/ld.so.c* /opt/glibc-2.14/etc/cp：是否覆盖”/opt/glibc-2.14/etc/ld.so.cache”？ ycp: 略过目录”/etc/ld.so.conf.d”[root@localhost glibc-2.14]# ln -sf /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.67.查看当前版本库的支持[root@localhost glibc-2.14]# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_PRIVATE8.恭喜完成操作，您可以继续其他操作了。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring自动组件扫描]]></title>
    <url>%2F2015%2F12%2F29%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%E8%87%AA%E5%8A%A8%E7%BB%84%E4%BB%B6%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[通常情况下，在XML bean配置文件声明所有的Bean类或组件，这样Spring容器可以检测并注册Bean类或组件。 其实，Spring是能够自动扫描，检测和预定义的项目包并实例化bean，不再有繁琐的Bean类声明在XML文件中。 1. 开启Spring自动扫描功能在bean配置文件中配置“context:component”表亲啊，这意味着，在 Spring 中启用自动扫描功能。base-package 是指明存储组件，Spring将扫描该文件夹，并找出Bean(注解为@Component)并注册到 Spring 容器： 1234567891011&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd"&gt; &lt;context:component-scan base-package="com.myprj.customer" /&gt;&lt;/beans&gt; 2. 使用@Component注解使用@Component注释来表示该类是一个自动扫描组件。 3. 自定义自动扫描组件名称你可以这样创建自定义名称： 123@Service("AAA")public class CustomerService ... 现在，可以用’AAA’这个名称进行检索。 1CustomerService cust = (CustomerService)context.getBean("AAA"); 4. 自动组件扫描注释类型在Spring2.5中，有4种类型的组件自动扫描注释类型 @Component – 指示自动扫描组件。 @Repository – 表示在持久层DAO组件。 @Service – 表示在业务层服务组件。 @Controller – 表示在表示层控制器组件。 5. Spring过滤器组件自动扫描5.1 过滤组件 - 包含使用Spring “过滤” 扫描并注册匹配定义“regex”，即使该类组件的名称未标注 @Component 也能被注册到Spring容器中： 123456789 &lt;context:component-scan base-package="com.myprj" &gt; &lt;context:include-filter type="regex" expression="com.myprj.customer.dao.*DAO.*" /&gt; &lt;context:include-filter type="regex" expression="com.myprj.customer.services.*Service.*" /&gt;&lt;/context:component-scan&gt; 在这个XML过滤中，所有文件的名称中包含 DAO 或 Service(DAO., Services.) 单词将被检测并在 Spring 容器中注册。 5.2 过滤组件 - 不包含另外，您还可以排除指定组件，以避免 Spring 检测和 Spring 容器注册。 如不包括在这些文件中标注有 @Service : 1234&lt;context:component-scan base-package="com.myprj.customer" &gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Service" /&gt; &lt;/context:component-scan&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 自动封装Bean]]></title>
    <url>%2F2015%2F10%2F29%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%E8%87%AA%E5%8A%A8%E5%B0%81%E8%A3%85Bean%2F</url>
    <content type="text"><![CDATA[在Spring框架中，可以用auto—wiring功能自动装配Bean。要启用它，只需要在xml配置文件中标签定义“autowire”属性： 1&lt;bean id="customer" class="com.myprj.common.Customer" autowire="byName" /&gt; 在Spring中，支持5中自动装配模式： 示例：Customer和Person对象的自动装配示例 123456789101112131415package com.myprj.common;public class Customer &#123; private Person person; public Customer(Person person) &#123; this.person = person; &#125; public void setPerson(Person person) &#123; this.person = person; &#125; //...&#125; 123456package com.myprj.common;public class Person &#123; //...&#125; 一、Auto-Wiring ‘no’ 这是默认模式，你需要通过‘ref’属性来连接bean： 12345&lt;bean id="customer" class="com.myprj.common.Customer"&gt; &lt;property name="person" ref="person" /&gt; &lt;/bean&gt; &lt;bean id="person" class="com.myprj.common.Person" /&gt; 二、Auto-Wiring ‘byName’ 按属性名称自动装配。在这种情况下，由于对“person” bean的名称是相同于“customer” bean 的属性(“person”)名称，所以，Spring会自动通过setter方法将其装配 – “setPerson(Person person)“： 12&lt;bean id="customer" class="com.myprj.common.Customer" autowire="byName" /&gt; &lt;bean id="person" class="com.myprj.common.Person" /&gt; 三、Auto-Wiring ‘byType’ 通过按属性的数据类型自动装配Bean。在这种情况下，由于“Person” bean中的数据类型是与“customer” bean的属性(Person对象)的数据类型一样的，所以，Spring会自动通过setter方法将其自动装配。– “setPerson(Person person)“： 12&lt;bean id="customer" class="com.myprj.common.Customer" autowire="byType" /&gt;&lt;bean id="person" class="com.myprj.common.Person" /&gt; 四、Auto-Wiring ‘constructor’ 通过构造函数参数的数据类型按属性自动装配Bean。在这种情况下，由于“person” bean的数据类型与“customer” bean的属性(Person对象)的构造函数参数的数据类型是一样的，所以，Spring通过构造方法自动装配 – “public Customer(Person person)“： 123&lt;bean id="customer" class="com.myprj.common.Customer" autowire="constructor" /&gt; &lt;bean id="person" class="com.myprj.common.Person" /&gt; 五、Auto-Wiring ‘autodetect’ “通过构造函数自动装配”是指选，如果默认构造函数(参数与任何数据类型)不匹配时，以其他方式使用“按类型自动装配”： 123&lt;bean id="customer" class="com.myprj.common.Customer" autowire="autodetect" /&gt; &lt;bean id="person" class="com.myprj.common.Person" /&gt; 六、Spring使用@Autowired注解自动装配 在Spring中，可以使用@Autowired注解通过setter方法、构造函数或字段自动装配Bean，注意：@Autowired注解是通过匹配数据类型自动装配Bean的。 1. 注册AutowiredAnnotationBeanPostProcessor要启用@Autowired，必须注册“AutowiredAnnotationBeanPostProcessor”,，你可以用以下两种方式做到这一点： 1.1 Include&lt;context:annotation-config /&gt;在Bean配置文件中添加Spring上下文和&lt;context:annotation-config /&gt;： 1234567891011&lt;beans //... xmlns:context=&quot;http://www.springframework.org/schema/context&quot; //... http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd&quot;&gt; //... &lt;context:annotation-config /&gt; //...&lt;/beans&gt; 1.2 包含 AutowiredAnnotationBeanPostProcessor直接在bean配置文件包含“AutowiredAnnotationBeanPostProcessor”： 1234567891011&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd&quot;&gt;&lt;bean class=&quot;org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor&quot;/&gt; //... &lt;/beans&gt; 2. @Autowired使用现在，你可以通过 @Autowired 自动装配 bean，它可以在 setter 方法，构造函数或字段中使用。 2.1 依赖检查默认情况下，@Autowired将执行相关检查，以确保属性已经装配正常。当Spring无法找到匹配的Bean装配，它会抛出异常。要解决这个问题，可以通过 @Autowired 的“required”属性设置为false来禁用此检查功能，如下，如果Spring不能找到一个匹配的Bean，person属性将不设定： 12@Autowired(required=false)private Person person; 2.2 @Qualifier@Qualifier注解我们用来控制bean应在字段上自动装配。例如，具有两个类似的 person bean 配置文件： 12345678910111213141516171819202122232425262728&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd"&gt; &lt;context:annotation-config /&gt; &lt;bean id="CustomerBean" class="com.myprj.common.Customer"&gt; &lt;property name="action" value="buy" /&gt; &lt;property name="type" value="1" /&gt; &lt;/bean&gt; &lt;bean id="PersonBean1" class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprj-1" /&gt; &lt;property name="address" value="address-1" /&gt; &lt;property name="age" value="29" /&gt; &lt;/bean&gt; &lt;bean id="PersonBean2" class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprj-2" /&gt; &lt;property name="address" value="address-2" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/beans&gt; Spring知道哪个 bean 应当装配？ 为了解决这个问题，可以使用 @Qualifier 自动装配一个特定的 bean，例如： 1234567891011121314package com.myprj.common;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;public class Customer &#123; @Autowired @Qualifier("PersonBean1") private Person person; private int type; private String action; //getter and setter methods&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 依赖注入（DI）]]></title>
    <url>%2F2015%2F10%2F29%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%20%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%EF%BC%88DI%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在Spring框架中，依赖注入（DI）的设计模式是用来定义对象之间的依赖关系，它主要有两种类型： Setter方法注入 构造器注入 一、Setter方法注入这是Spring最流行的注入方式。 二、构造器注入1234567891011121314&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="OutputHelper" class="com.yiibai.output.OutputHelper"&gt; &lt;constructor-arg&gt; &lt;ref bean="JsonOutputGenerator" /&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id="JsonOutputGenerator" class="com.yiibai.output.impl.JsonOutputGenerator" /&gt;&lt;/beans&gt; 一个类包含多个构造函数所带的参数不同，它总是会造成构造函数注入参数类型歧义的问题，请务必在标签中添加type属性： 123&lt;constructor-arg type="java.lang.String"&gt; &lt;value&gt;hello&lt;/value&gt;&lt;/constructor-arg&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java与设计模式]]></title>
    <url>%2F2015%2F10%2F29%2Fmd_Java%E9%9D%A2%E8%AF%95%E7%BB%83%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93%2FJava%E4%B8%8E%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%80%2F</url>
    <content type="text"><![CDATA[设计模式是解决问题的方案，学习现有的设计模式可以做到经验复用；使用设计模式可以重用代码，让代码更容易被他人理解，也保证了代码的可靠性。Java设计模式总体上分为三大类：创建型模式、结构型模式、行为型模式，而每一大类都细分有多种设计模式，每种模式都有相应的原理与之对应。 1. 单例模式（Singleton）1.1 单例模式的特点 单例类只能有一个实例； 单例类必须自己创建自己的唯一实例； 单例类必须给所有其他对象提供这一实例。 1.2 Java单例模式Java的单例模式实现方式有四种：饿汉模式、懒汉模式、静态内部类、枚举类；使用一个私有构造函数、一个私有静态变量以及一个公有静态函数来实现。 Ⅰ. 懒汉式——线程不安全懒汉式的私有静态单例被延迟实例化，当没有用到该类时将不会被实例化，达到节约资源的目的；缺点是如果多个线程同时访问可能导致单例被多次实例化。 123456789101112131415/** * 1、懒汉模式-线程不安全 */class Singleton01&#123; private static Singleton01 singleton; private Singleton01()&#123; &#125; public static Singleton01 getSingleton()&#123; if (null == singleton)&#123; singleton = new Singleton01(); &#125; return singleton; &#125;&#125; Ⅱ. 饿汉式——线程安全饿汉式是在类加载时直接实例化该单例类达到线程安全的目的，但这样直接实例化的方式失去了延迟实例化带来的节约资源的好处。 123456789101112/** * 2、饿汉模式-线程安全,不够节约资源 */class Singleton02&#123; private static Singleton02 singleton = new Singleton02(); private Singleton02()&#123; &#125; public static Singleton02 getSingleton()&#123; return singleton; &#125;&#125; Ⅲ. 懒汉式——线程安全只需要对获取单例的公有方法加锁，使得在一个时间点只能有一个线程进入该方法，从而避免了被多次实例化；但当一个线程进入该方法后，其他试图进入的线程都必须等待，这样会让线程阻塞时间过长，所以不推荐使用。 123456789101112131415/** * 3、懒汉模式-线程安全,会导致线程阻塞 */class Singleton03&#123; private static Singleton03 singleton; private Singleton03()&#123; &#125; public static synchronized Singleton03 getSingleton()&#123; if (null == singleton)&#123; singleton = new Singleton03(); &#125; return singleton; &#125;&#125; Ⅳ. 懒汉式双重校验锁——线程安全加锁操作只需要对实例化的那部分代码进行，双重校验锁先判断单例是否已经被实例化，如果没有被实例化，那么才对实例化语句进行加锁。 123456789101112131415161718192021222324252627/** * 4、双重校验锁-线程安全 * 1).判断是否被实例化，再对实例化语句加锁； * 2).内部再次进行判断是否实例化，并加锁； * 3).为单例对象添加采用 volatile 关键字修饰，禁止JVM的指令重排。 */class Singleton04&#123; private volatile static Singleton04 singleton; private Singleton04()&#123; // 防反射 if(null !=singleton)&#123; throw Exception(); &#125; &#125; public static Singleton04 getSingleton()&#123; if (null == singleton)&#123; synchronized (Singleton04.class)&#123; if (null == singleton)&#123; synchronized (Singleton04.class)&#123; singleton = new Singleton04(); &#125; &#125; &#125; &#125; return singleton; &#125;&#125; singleton 采用 volatile 关键字修饰也是很有必要的， singleton = new Singleton4(); 这段代码其实是分为三步执行： 为 singleton 分配内存空间 初始化 singleton 将 singleton 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1&gt;3&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getSingleton() 后发现 singleton 不为空，因此返回 singleton，但此时 singleton 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 Ⅴ. 静态内部类实现当 Singleton 类加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 getUniqueInstance() 方法从而触发 SingletonHolder.INSTANCE 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例，并且 JVM 能确保 INSTANCE 只被实例化一次。 这种方式不仅具有延迟初始化的好处，而且由 JVM 提供了对线程安全的支持。 12345678910111213141516/** * 5、静态内部类实现 */public class Singleton &#123; private Singleton() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getUniqueInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; Ⅵ. 枚举类实现使用枚举来实现单实例控制会更加简洁，而且无偿地提供了序列化机制，并由JVM从根本上提供保障，可以防止反射攻击，绝对防止多次实例化，是更简洁、高效、安全的实现单例的方式。 123456789101112public enum Singleton &#123; /** * 定义一个枚举的元素，它就代表了Singleton的一个实例。 */ INSTANCE; /** * 单例可以有自己的操作 */ public void singletonOperation()&#123; //功能处理 &#125;&#125; 2. 责任链模式（Chain Of Responsibility）责任链模式是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。 2.1 责任链模式的结构 抽象处理者(Handler)角色：定义出一个处理请求的接口。如果需要，接口可以定义 出一个方法以设定和返回对下家的引用。 具体处理者(ConcreteHandler)角色：具体处理者接到请求后，可以选择将请求处理掉，或者将请求传给下家。由于具体处理者持有对下家的引用，因此，如果需要，具体处理者可以访问下家。 2.2 Java责任链模式1234567891011121314/** * 抽象处理者角色 */public abstract class Handler &#123; //1.持有后继的责任对象 protected Handler successor; //2.构造处理对象并传入下家引用 public Handler(Handler successor) &#123; this.successor = successor; &#125; //3.示意处理请求的方法 protected abstract void handleRequest(Request request);&#125; 12345678910111213141516171819202122/** * 具体处理者角色1 */public class ConcreteHandler1 extends Handler &#123; //1.构造处理对象并传入下家引用，可以传入空值null public ConcreteHandler1(Handler successor) &#123; super(successor); &#125; //2.具体处理请求的方法 @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE1) &#123;//处理自己所能处理的请求 System.out.println(request.getName() + " is handle by ConcreteHandler1"); return; &#125; //3.判断是否有后继的责任对象，如果有，就转发请求给后继的责任对象。 if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 12345678910111213141516171819202122/** * 具体处理者角色2 */public class ConcreteHandler2 extends Handler &#123; //1.构造处理对象并传入下家引用，可以传入空值null public ConcreteHandler2(Handler successor) &#123; super(successor); &#125; //2.具体处理请求的方法 @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE2) &#123;//处理自己所能处理的请求 System.out.println(request.getName() + " is handle by ConcreteHandler2"); return; &#125; //3.判断是否有后继的责任对象，如果有，就转发请求给后继的责任对象。 if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125; 123456789101112131415161718192021222324/** * 请求 */public class Request &#123; private RequestType type; private String name; public Request(RequestType type, String name) &#123; this.type = type; this.name = name; &#125; public RequestType getType() &#123; return type; &#125; public String getName() &#123; return name; &#125;&#125; 123public enum RequestType &#123; TYPE1, TYPE2&#125; 1234567891011121314151617/** * 客户类 */public class Client &#123; public static void main(String[] args) &#123; //1.组装责任链 Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); //2.构建请求 Request request1 = new Request(RequestType.TYPE1, "request1"); Request request2 = new Request(RequestType.TYPE2, "request2"); //3.处理请求 handler2.handleRequest(request1); handler2.handleRequest(request2); &#125;&#125; 123运行结果：request1 is handle by ConcreteHandler1request2 is handle by ConcreteHandler2 3. 迭代器模式（Iterator）迭代器模式又叫游标(Cursor)模式，是对象的行为模式。迭代器模式可以顺序地访问一个聚集中的元素而不必暴露聚集的内部表象（internal representation）。 3.1 迭代器模式的结构 抽象迭代子(Iterator)角色：此抽象角色定义出遍历元素所需的接口。 具体迭代子(ConcreteIterator)角色：此角色实现了Iterator接口，并保持迭代过程中的游标位置。 聚集(Aggregate)角色：此抽象角色给出创建迭代子(Iterator)对象的接口。 具体聚集(ConcreteAggregate)角色：实现了创建迭代子(Iterator)对象的接口，返回一个合适的具体迭代子实例。 客户端(Client)角色：持有对聚集及其迭代子对象的引用，调用迭代子对象的迭代接口，也有可能通过迭代子操作聚集元素的增加和删除。 3.2 Java迭代器模式1234567891011/** * 抽象迭代器角色类 */public interface Iterator&lt;Item&gt; &#123; Item next(); boolean hasNext(); //还可以定义一些其他迭代方法：移动到第一个元素、返回当前元素、是否为最后一个元素等等。&#125; 12345678910111213141516171819202122/** * 具体迭代器角色类 */public class ConcreteIterator&lt;Item&gt; implements Iterator &#123; private Item[] items; private int position = 0; public ConcreteIterator(Item[] items) &#123; this.items = items; &#125; @Override public Object next() &#123; return items[position++]; &#125; @Override public boolean hasNext() &#123; return position &lt; items.length; &#125;&#125; 1234567/** * 聚合类接口 */public interface Aggregate &#123; //工厂方法，创建相应迭代子对象的接口 Iterator createIterator();&#125; 12345678910111213141516171819/** * 具体聚合类 */public class ConcreteAggregate implements Aggregate &#123; private Integer[] items; //构造方法，构建（或传入）聚合对象的具体内容 public ConcreteAggregate() &#123; items = new Integer[10]; for (int i = 0; i &lt; items.length; i++) &#123; items[i] = i; &#125; &#125; @Override public Iterator createIterator() &#123; return new ConcreteIterator&lt;Integer&gt;(items); &#125;&#125; 12345678910111213/** * 客户类 */public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new ConcreteAggregate(); Iterator&lt;Integer&gt; iterator = aggregate.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; 4. 模板方法模式（Template Method）模板方法模式是类的行为模式。准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。这就是模板方法模式的用意。 4.1 模板方法模式的结构 抽象模板(Abstract Template)角色有如下责任： ■ 定义了一个或多个抽象操作，以便让子类实现。这些抽象操作叫做基本操作，它们是一个顶级逻辑的组成步骤。 ■ 定义并实现了一个模板方法。这个模板方法一般是一个具体方法，它给出了一个顶级逻辑的骨架，而逻辑的组成步骤在相应的抽象操作中，推迟到子类实现。顶级逻辑也有可能调用一些具体方法。 具体模板(Concrete Template)角色有如下责任： ■ 实现父类所定义的一个或多个抽象方法，它们是一个顶级逻辑的组成步骤。 ■ 每一个抽象模板角色都可以有任意多个具体模板角色与之对应，而每一个具体模板角色都可以给出这些抽象方法（也就是顶级逻辑的组成步骤）的不同实现，从而使得顶级逻辑的实现各不相同。 4.2 Java模板方法模式如下给出例子：冲咖啡和冲茶都有类似的流程，但是某些步骤会有点不一样，要求复用那些相同步骤的代码。 12345678910111213141516171819202122232425262728293031323334/** * 抽象模板角色类 */public abstract class CaffeineBeverage &#123; /** * 模板方法 */ final void prepareRecipe() &#123; boilWater(); brew(); pourInCup(); addCondiments(); &#125; /** * 基本方法的声明（泡） */ abstract void brew(); /** * 基本方法的声明（加料） */ abstract void addCondiments(); /** * 基本方法的声明（烧水） */ void boilWater() &#123; System.out.println("boilWater"); &#125; /** * 基本方法的声明（倒入杯中） */ void pourInCup() &#123; System.out.println("pourInCup"); &#125;&#125; 1234567891011121314/** * 具体模板角色类——泡咖啡 */public class Coffee extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println("Coffee.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Coffee.addCondiments"); &#125;&#125; 1234567891011121314/** * 具体模板角色类——泡茶 */public class Tea extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println("Tea.brew"); &#125; @Override void addCondiments() &#123; System.out.println("Tea.addCondiments"); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java面试练习与总结</tag>
        <tag>Java设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Bean基础]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%20Bean%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一、Spring Bean引用例子1. Bean在不同的XML 文件如果实在不同的XML配置文件中的Bean，可以用一个标签，“bean”属性引用它： 12345&lt;bean id="OutputHelper" class="com.myprj.output.OutputHelper"&gt; &lt;property name="outputGenerator" &gt; &lt;ref bean="CsvOutputGenerator"/&gt; &lt;/property&gt;&lt;/bean&gt; 2. 在同一个XML文件中的Bean如果引用在同一个XML文件中的bean，你可以用 ‘ref’ 标签，“local”属性引用它，使用时常省略。 1&lt;ref local="someBean"/&gt; 二、如何注入值到Spring Bean属性在Spring中，有三种方式将值注入到Bean的属性： 正常方式 快速方式 “p”模式方式 如下一个简单的Java类，包含两个数属性：name和type，稍后使用Spring注入值到这个Bean的属性： 1234567891011121314151617181920package com.myprj.common;public class FileNameGenerator &#123; private String name; private String type; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125;&#125; 1. 正常方式在标签中的标签中赋值： 12345678&lt;bean id="FileNameGenerator" class="com.myprj.common.FileNameGenerator"&gt; &lt;property name="name"&gt; &lt;value&gt;myprj&lt;/value&gt; &lt;/property&gt; &lt;property name="type"&gt; &lt;value&gt;txt&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 2. 快速方式在标签中的“value”属性赋值： 1234&lt;bean id="FileNameGenerator" class="com.myprj.common.FileNameGenerator"&gt; &lt;property name="name" value="myprj" /&gt; &lt;property name="type" value="txt" /&gt;&lt;/bean&gt; 3. “p”模式方式通过标签中p模式赋值： 1234//...xmlns:p="http://www.springframework.org/schema/p"//...&lt;bean id="FileNameGenerator" class="com.myprj.common.FileNameGenerator" p:name="myprj" p:type="txt" /&gt; 三、Spring Bean加载多个配置文件123456&lt;beans //... &lt;import resource="common/Spring-Common.xml"/&gt; &lt;import resource="connection/Spring-Connection.xml"/&gt; &lt;import resource="moduleA/Spring-ModuleA.xml"/&gt;&lt;/beans&gt; 四、Spring 内部Bean实例在Spring框架中，一个bean仅用于一个特定的属性，这是提醒其声明为一个内部bean。内部bean支持setter注入“property”和构造器注入”constructor-arg“。 如下几种方式将达到同样的效果： 使用 标签和“ref”属性： 123456789&lt;bean id="CustomerBean" class="com.myprj.common.Customer"&gt; &lt;property name="person" ref="PersonBean" /&gt;&lt;/bean&gt;&lt;bean id="PersonBean" class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprj" /&gt; &lt;property name="address" value="address1" /&gt; &lt;property name="age" value="28" /&gt;&lt;/bean&gt; 使用内部Bean方式： 123456789&lt;bean id="CustomerBean" class="com.myprj.common.Customer"&gt; &lt;property name="person"&gt; &lt;bean class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprj" /&gt; &lt;property name="address" value="address1" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; 内部 bean 也支持构造器注入： 123456789&lt;bean id="CustomerBean" class="com.myprj.common.Customer"&gt; &lt;constructor-arg&gt; &lt;bean class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprj" /&gt; &lt;property name="address" value="address1" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 五、Spring Bean作用域实例在Spring中，Bean作用域用来确定那种类型的Bena实例应该被Spring的容器返回给调用者。Spring Bean支持的5种作用域： 单例——每个Spring IoC容器返回一个Bean实例； 原型——每次请求时返回一个新的Bean实例； 请求——返回每个HTTP请求的一个Bean实例； 会话——返回每个HTTP会话的一个Bean实例； 全局会话——返回全局HTTP会话的一个Bean实例。 在大多数情况下，可能只处理了 Spring 的核心作用域 - 单例和原型，默认作用域是单例。 这里有一个例子来说明，bean的作用域单例和原型之间的不同： 1234567891011121314package com.myprj.customer.services;public class CustomerService &#123; String message; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125;&#125; 1. 单例实例如果Bean配置文件中没有指定Bean的范围，默认为单例； 123456789&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService" /&gt; &lt;/beans&gt; 执行代码： 1234567891011121314151617181920212223package com.myprj.common;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.myprj.customer.services.CustomerService;public class App &#123; public static void main( String[] args ) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123;"Spring-Customer.xml"&#125;); CustomerService custA = (CustomerService)context.getBean("customerService"); custA.setMessage("Message by custA"); System.out.println("Message : " + custA.getMessage()); //retrieve it again CustomerService custB = (CustomerService)context.getBean("customerService"); System.out.println("Message : " + custB.getMessage()); &#125;&#125; 输出结果： 12Message : Message by custAMessage : Message by custA 在单例中，每个Spring IoC容器只有一个实例，无论多少次调用getBean()方法获取它，总是返回同一个实例。 2. 原型实例如果每次获取Bean对象时需要一个新的Bean实例，需要在bean配置中添加“scope”属性，值为“prototype”（原型）。 123456789&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService" scope="prototype"/&gt; &lt;/beans&gt; 运行代码并执行： 12Message : Message by custAMessage : null 3. Bean作用域注解在此之前在XML配置文件中启用自动组件扫描： 1&lt;context:component-scan base-package="com.myprj.customer" /&gt; 使用注解定义Bean的作用域： 12345678910111213141516171819package com.myprj.customer.services;import org.springframework.context.annotation.Scope;import org.springframework.stereotype.Service;@Service@Scope("prototype")public class CustomerService &#123; String message; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125;&#125; 六、Spring集合（List、Set、Map、Properties）实例以下例子将展示Spring如何注入值到集合中。 Spring Beans: 12345678910111213141516package com.myprj.common;import java.util.List;import java.util.Map;import java.util.Properties;import java.util.Set;public class Customer &#123; private List&lt;Object&gt; lists; private Set&lt;Object&gt; sets; private Map&lt;Object, Object&gt; maps; private Properties pros; //...&#125; 1. List示例1234567891011&lt;property name="lists"&gt; &lt;list&gt; &lt;value&gt;1&lt;/value&gt; &lt;ref bean="PersonBean" /&gt; &lt;bean class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprjList" /&gt; &lt;property name="address" value="Hainan" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; 2. Set示例1234567891011&lt;property name="sets"&gt; &lt;set&gt; &lt;value&gt;1&lt;/value&gt; &lt;ref bean="PersonBean" /&gt; &lt;bean class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprjSet" /&gt; &lt;property name="address" value="Hainan" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; 3. Map示例12345678910111213&lt;property name="maps"&gt; &lt;map&gt; &lt;entry key="Key 1" value="1" /&gt; &lt;entry key="Key 2" value-ref="PersonBean" /&gt; &lt;entry key="Key 3"&gt; &lt;bean class="com.myprj.common.Person"&gt; &lt;property name="name" value="myprjMap" /&gt; &lt;property name="address" value="Hainan" /&gt; &lt;property name="age" value="28" /&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; 4. Properties示例123456&lt;property name="pros"&gt; &lt;props&gt; &lt;prop key="admin"&gt;admin@myprj.com&lt;/prop&gt; &lt;prop key="support"&gt;support@myprj.com&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 七、Spring注入日期到Bean属性当我们有个Bean属性需要注入时间日期时： 12345678910111213141516171819202122package com.myprj.common;import java.util.Date;public class Customer &#123; Date date; public Date getDate() &#123; return date; &#125; public void setDate(Date date) &#123; this.date = date; &#125; @Override public String toString() &#123; return "Customer [date=" + date + "]"; &#125;&#125; 简单的如下配置将会出现错误： 123&lt;bean id="customer" class="com.myprj.common.Customer"&gt; &lt;property name="date" value="2015-12-31" /&gt;&lt;/bean&gt; 解决办法：在Spring中可以通过两种方式注入时间日期： 1. Factory Bean声明一个dateFormat工厂Bean，该工厂实例为SimpleDateFormat类型，传入时间日期格式字符串构造对象；在“customer”Bean中引入dateFormat Bean，并调用parse()方法将字符串转换为Date对象： 1234567891011&lt;bean id="dateFormat" class="java.text.SimpleDateFormat"&gt; &lt;constructor-arg value="yyyy-MM-dd" /&gt;&lt;/bean&gt;&lt;bean id="customer" class="com.myprj.common.Customer"&gt; &lt;property name="date"&gt; &lt;bean factory-bean="dateFormat" factory-method="parse"&gt; &lt;constructor-arg value="2018-12-31" /&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 2. CustomDateEditor1234567891011121314151617181920212223242526&lt;!--声明一个 CustomDateEditor 类将字符串转换成 java.util.Date--&gt;&lt;bean id="dateEditor" class="org.springframework.beans.propertyeditors.CustomDateEditor"&gt; &lt;constructor-arg&gt; &lt;bean class="java.text.SimpleDateFormat"&gt; &lt;constructor-arg value="yyyy-MM-dd" /&gt; &lt;/bean&gt; &lt;/constructor-arg&gt; &lt;constructor-arg value="true" /&gt;&lt;/bean&gt;&lt;!--并声明另一个“CustomEditorConfigurer”，使用Spring转换 bean 属性，其类型为java.util.Date--&gt;&lt;bean class="org.springframework.beans.factory.config.CustomEditorConfigurer"&gt; &lt;property name="customEditors"&gt; &lt;map&gt; &lt;entry key="java.util.Date"&gt; &lt;ref local="dateEditor" /&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="customer" class="com.myprj.common.Customer"&gt; &lt;property name="date" value="2018-12-31" /&gt;&lt;/bean&gt; 八、Spring PropertyPlaceholderConfigurer实例有些时候Spring开发人员会把项目的部署信息（数据库连接信息、日志文件的路径）写在XML bean配置文件中： 12345678910111213&lt;bean id="customerSimpleDAO" class="com.myprj.customer.dao.impl.SimpleJdbcCustomerDAO"&gt; &lt;property name="dataSource" ref="dataSource" /&gt;&lt;/bean&gt;&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/myprjjava" /&gt; &lt;property name="username" value="root" /&gt; &lt;property name="password" value="password" /&gt;&lt;/bean&gt; 但是，在实际企业环境下，项目部署信息不会出现在bean配置文件中，而是配置在一个单独的文件，如properties文件； PropertyPlaceholderConfigurer示例为了解决这个问题，可以使用 PropertyPlaceholderConfigurer 类通过一个特殊的格式在外部部署细节到一个属性(properties )文件，并在bean的配置文件中配置 ：${variable}。 创建一个属性文件(database.properties)，包含数据库的详细信息，把它放到你的项目类路径： 1234jdbc.driverClassName=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/myprj_dbjdbc.username=rootjdbc.password=123456 在bean配置文件中声明提供一个PropertyPlaceholderConfigurer映射到刚才创建的“database.properties”属性文件： 1234567&lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="location"&gt; &lt;value&gt;database.properties&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; 于是可以如下配置： 12345678&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClassName&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt;&lt;/bean&gt; 九、Spring的继承配置12345678&lt;bean id="BaseCustomerMalaysia" class="com.myprj.common.Customer"&gt; &lt;property name="country" value="Malaysia" /&gt;&lt;/bean&gt;&lt;bean id="CustomerBean" parent="BaseCustomerMalaysia"&gt; &lt;property name="action" value="buy" /&gt; &lt;property name="type" value="1" /&gt;&lt;/bean&gt; 十、Spring依赖检查在Spring中，可以使用依赖检查功能，以确保所要求的属性可设置或者注入。 4个依赖检查支持的模式： none – 没有依赖检查，这是默认的模式。 simple – 如果基本类型(int, long,double…)和集合类型(map, list..)的任何属性都没有设置，UnsatisfiedDependencyException将被抛出。 objects – 如果对象类型的任何属性都没有设置，UnsatisfiedDependencyException将被抛出。 all – 如果任何类型的任何属性都没有被设置，UnsatisfiedDependencyException将被抛出。 123456789101112&lt;bean id="xxxx" class="xxxxxr" dependency-check="simple"&gt; //...&lt;/bean&gt;&lt;bean id="xxxx" class="xxxxxr" dependency-check="objects"&gt; //...&lt;/bean&gt;&lt;bean id="xxxx" class="xxxxxr" dependency-check="all"&gt; //...&lt;/bean&gt; Spring使用@Required注解依赖检查在使用之前需要在Bean配置中包含&lt;context:annotation-config /&gt;或 12&lt;bean class=&quot;org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor&quot;/&gt; @Required使用在 setter方法或属性上，以确保该属性被注入值。 十一、Spring Bean InitializingBean和DisposableBean在Spring中，InitializingBean和DisposableBean是两个标记接口，为Spring执行时bean的初始化和销毁某些行为时的有用方法。 对于Bean实现 InitializingBean，它将在所有的 bean 属性被设置之后运行 afterPropertiesSet()。 对于 Bean 实现了DisposableBean，它将在 Spring 容器释放该 bean 之后运行 destroy()。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring xml 配置详解]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%20xml%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言​ 我们使用的Spring框架作为Bean的管理容器，其最经典最基础的Bean配置方式就是纯XML配置，这样做使得结构清晰明了，适合大型项目使用。Spring的XML配置虽然很繁琐，而且存在简洁的注解方式，但读懂XML配置文件对我们来说依然很重要，尚且对于老系统维护必不可少的面对XML配置。 ​ Spring的xml配置文件是其IOC容器启动时传入的重要配置文件，这样才能以次为基础创建一个容器，并且实例化、装配配置文件中的Bean。Spring 配置文件用于指导Spring 工厂生产Bean，并进行依赖关系的注入，以及Bean实例的分发。Spring默认使用applicationContext.xml配置文件，当然名字可以修改。 1. Spring xml文件头以下是Spring xml很常规的文件头，这样一大串内容另初学者很是费解，但仔细分析其结构理解起来也不难： 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd"&gt;&lt;/beans&gt; 首先我们需要了解xml本身的一些知识，这些知识跟Spring无关： 命名空间：这里命名空间的定义跟我们Java、C++的导包很相似，就是解决标签名的具体归属，规定xml中可以出现多少种的标签。这里，xml的命名空间用xmlns定义，一读便知是XML NameSpace的字母缩写。 语法：xmlns:[prefix]=”[url of name]”。其中，url of name是完整命名空间，而prefix是命名空间的别名。 头解析：如xmlns=”http://www.springframework.org/schema/beans&quot;，声明xml文件默认的命名空间，但凡之后没有指定命名空间的标签，全是出自这个命名空间；又如：xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;，引入XMLSchema-instance命名空间，并简称为xsi，显然也是取其首字母组成的。 模式内容xsi:schemaLocation：代表刚刚引入的XMLSchema-instance（简称xsi）中的schemaLocation属性，它的作用是将多个&lt;命名空间，模式位置&gt;对对应起来，其中命名空间和模式位置之间使用空白符分隔。 总结： 命名空间的定义分为了两个步骤： 指定命名空间的名称，需要指定命名空间的缩类名和全名 指定命名空间的schema文档样式文件的位置，用空格或回车行来进行分割。 指定命名空间schema地址有两个用途： xml解析器可以获取schema文件，并对文档进行格式合法性验证 在开发环境下，IDE可以用schema文件来对文档编辑器进行诱导功能。 2. Spring xml标签详解2.1 &lt;beans&gt;&lt;/beans&gt;Spring xml的beans标签相当于整个配置的父结构，它拥有相应的属性（attribute）对所辖的&lt;bean&gt;进行统一的默认行为设置，包括如下几个 default-lazy-init (false|true): 默认为false，用来标志是否对所有的bean进行延迟初始化。 default-autowire (no|byName|byType|constructor|autodetect): 默认为no，用来标志全体bean使用哪一种默认绑定方式。 default-dependency-check(none|objects|simple|all) : 默认为none，标志全体bean做不做依赖检查。 default-init-method : 如果所管辖的bean按照某种规则，都有同样名称的初始化方法的话，可以在这里统一制定这个初始化方法名，而不用在每个bean上都重复单独指定。 default-destroy-method: 同上，指定对象销毁的方法。 2.2 &lt;bean&gt;&lt;/bean&gt; id属性：每个注册到容器的对象都需要一个唯一标志来将其与其他bean区别开来。 class属性：每个注册到容器的对象都需要class属性指定其类型，否则，容器不知道这个对象到底是什么。 Spring的Bean配置的方式有很多种，具体有三：JAVA配置、注解配置、XML配置；详情参见Spring Bean基础。 2.3 Spring xml自定义标签我们经常使用一些依赖于Spring的组件时，发现可以通过自定义配置Spring标签来实现插件的注入，如数据源配置、MyBatis的配置、aop配置、事务tx配置等。Spring自定义标签配置步骤如下： 编写对应的java bean 提供一个xsd文件，负责对xml的标签&lt;datasource&gt;进行校验； 定义一个BeanDefinitionParser负责解析xml,并将必要的信息放入spring中； 定义个NamespaceHandler,由sping框架的调用入口。这也是我们自定义xml解析的入口； 配置schema和handler； 在spring的配置文件中使用标签。 详情参见：Spring下自定义xml标签，本人日后整理。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring JavaConfig实例]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%20JavaConfig%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[从Spring 3起，JavaConfig功能已经包含到Spring核心模块，他允许开发者以另一种方式定义装配Bean，并且仍然允许经典的XML配置文件方式来定义装配Bean ；所以JavaConfig是另一种替代解决方案，来看一下经典的XML定义和JavaConfig的不同，如下定义Spring容器中的Bean： Spring XML File——applicationContext.xml: 12345678&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="helloBean" class="com.myprj.hello.impl.HelloWorldImpl"&gt; &lt;/beans&gt; 等效于以下JavaConfig配置： 12345678910111213141516package com.myprj.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.myprj.hello.HelloWorld;import com.myprj.hello.impl.HelloWorldImpl;@Configurationpublic class AppConfig &#123; @Bean(name="helloBean") public HelloWorld helloWorld() &#123; return new HelloWorldImpl(); &#125; &#125; @Import实例一般来说, 需要按模块或类别分割Spring XML Bean文件成多个小文件, 使事情更容易维护和模块化。 例如， 123456789&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;import resource="config/customer.xml"/&gt; &lt;import resource="config/scheduler.xml"/&gt; &lt;/beans&gt; 它等效于Spring3 JavaConfig @Import 功能： 12345678910package com.myprj.config;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;@Configuration@Import(&#123; CustomerConfig.class, SchedulerConfig.class &#125;)public class AppConfig &#123; &#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP+AspectJ注解实例]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FSpring%20AOP%2BAspectJ%E6%B3%A8%E8%A7%A3%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[本文展示如何将AspectJ注解集成到Spring AOP框架。在这个Spring AOP+ AspectJ 示例中，让您轻松实现拦截方法。 常见AspectJ的注解： @Before – 方法执行前运行 @After – 运行在方法返回结果后 @AfterReturning – 运行在方法返回一个结果后，在拦截器返回结果。 @AfterThrowing – 运行方法在抛出异常后， @Around – 围绕方法执行运行，结合以上这三个通知。 注意 Spring AOP 中没有 AspectJ 支持，请阅读前文AOP面向切面编程。 1. 启用AspectJ在 Spring 配置文件，把“&lt;aop:aspectj-autoproxy /&gt;”，并定义Aspect(拦截)和普通的bean。 File : applicationContext.xml 12345678910111213141516&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd "&gt; &lt;aop:aspectj-autoproxy /&gt; &lt;bean id="customerBo" class="com.myprj.customer.bo.impl.CustomerBoImpl" /&gt; &lt;!-- Aspect --&gt; &lt;bean id="logAspect" class="com.myprj.aspect.LoggingAspect" /&gt;&lt;/beans&gt; 2. AspectJ @Before在下面例子中，logBefore()方法将在 customerBo接口的 addCustomer()方法的执行之前被执行。 AspectJ的“切入点”是用来声明哪种方法将被拦截]，支持切入点表达式的完整列表。 File : LoggingAspect.java 123456789101112131415161718package com.myprj.aspect;import org.aspectj.lang.Joinmyprj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;@Aspectpublic class LoggingAspect &#123; @Before("execution(* com.myprj.customer.bo.CustomerBo.addCustomer(..))") public void logBefore(Joinmyprj joinmyprj) &#123; System.out.println("logBefore() is running!"); System.out.println("hijacked : " + joinmyprj.getSignature().getName()); System.out.println("******"); &#125;&#125; 运行 12CustomerBo customer = (CustomerBo) appContext.getBean("customerBo");customer.addCustomer(); 输出结果 1234logBefore() is running!hijacked : addCustomer******addCustomer() is running 3. AspectJ @After在下面例子中，logAfter()方法将在 customerBo 接口的 addCustomer()方法的执行之后执行。 File : LoggingAspect.java 12345678910111213141516171819package com.myprj.aspect;import org.aspectj.lang.Joinmyprj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.After;@Aspectpublic class LoggingAspect &#123; @After("execution(* com.myprj.customer.bo.CustomerBo.addCustomer(..))") public void logAfter(Joinmyprj joinmyprj) &#123; System.out.println("logAfter() is running!"); System.out.println("hijacked : " + joinmyprj.getSignature().getName()); System.out.println("******"); &#125;&#125; 运行它 12CustomerBo customer = (CustomerBo) appContext.getBean(&quot;customerBo&quot;);customer.addCustomer(); 输出结果 1234addCustomer() is running logAfter() is running!hijacked : addCustomer****** 4. AspectJ @AfterReturning在下面例子中，logAfterReturning()方法将在 customerBo 接口的addCustomerReturnValue()方法执行之后执行。此外，还可以截取返回的值使用“returning”属性。 要截取返回的值，对“returning”属性(结果)的值必须用相同的方法参数(结果)。 File : LoggingAspect.java 1234567891011121314151617181920package com.myprj.aspect;import org.aspectj.lang.Joinmyprj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.AfterReturning;@Aspectpublic class LoggingAspect &#123; @AfterReturning( pointcut = "execution(* com.myprj.customer.bo.CustomerBo.addCustomerReturnValue(..))", returning= "result") public void logAfterReturning(Joinmyprj joinmyprj, Object result) &#123; System.out.println("logAfterReturning() is running!"); System.out.println("hijacked : " + joinmyprj.getSignature().getName()); System.out.println("Method returned value is : " + result); System.out.println("******"); &#125;&#125; 运行它 12CustomerBo customer = (CustomerBo) appContext.getBean(&quot;customerBo&quot;); customer.addCustomerReturnValue(); 输出结果 12345addCustomerReturnValue() is running logAfterReturning() is running!hijacked : addCustomerReturnValueMethod returned value is : abc****** 5. AspectJ @AfterReturning在下面的例子中，如果 customerBo 接口的addCustomerThrowException()方法抛出异常logAfterThrowing()方法将被执行。 File : LoggingAspect.java 123456789101112131415161718192021package com.myprj.aspect;import org.aspectj.lang.Joinmyprj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.AfterThrowing;@Aspectpublic class LoggingAspect &#123; @AfterThrowing( pointcut = "execution(* com.myprj.customer.bo.CustomerBo.addCustomerThrowException(..))", throwing= "error") public void logAfterThrowing(Joinmyprj joinmyprj, Throwable error) &#123; System.out.println("logAfterThrowing() is running!"); System.out.println("hijacked : " + joinmyprj.getSignature().getName()); System.out.println("Exception : " + error); System.out.println("******"); &#125;&#125; 运行它 12CustomerBo customer = (CustomerBo) appContext.getBean(&quot;customerBo&quot;);customer.addCustomerThrowException(); 输出结果 1234567addCustomerThrowException() is running logAfterThrowing() is running!hijacked : addCustomerThrowExceptionException : java.lang.Exception: Generic Error******Exception in thread &quot;main&quot; java.lang.Exception: Generic Error //... 6. AspectJ @Around在下面例子中，logAround()方法将在customerBo接口的addCustomerAround()方法执行之前执行， 必须定义“joinmyprj.proceed();” 控制何时拦截器返回控制到原来的addCustomerAround()方法。 File : LoggingAspect.java 12345678910111213141516171819202122232425package com.myprj.aspect;import org.aspectj.lang.ProceedingJoinmyprj;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Around;@Aspectpublic class LoggingAspect &#123; @Around("execution(* com.myprj.customer.bo.CustomerBo.addCustomerAround(..))") public void logAround(ProceedingJoinmyprj joinmyprj) throws Throwable &#123; System.out.println("logAround() is running!"); System.out.println("hijacked method : " + joinmyprj.getSignature().getName()); System.out.println("hijacked arguments : " + Arrays.toString(joinmyprj.getArgs())); System.out.println("Around before is running!"); joinmyprj.proceed(); //continue on the intercepted method System.out.println("Around after is running!"); System.out.println("******"); &#125; &#125; 运行它 12CustomerBo customer = (CustomerBo) appContext.getBean(&quot;customerBo&quot;);customer.addCustomerAround(&quot;myprj&quot;); 输出结果 1234567logAround() is running!hijacked method : addCustomerAroundhijacked arguments : [myprj]Around before is running!addCustomerAround() is running, args : myprjAround after is running!****** 总结如今总是建议采用最少 AspectJ 注解。这是关于Spring AspectJ 的一篇相当长的文章。进一步的解释和例子，请访问下面的参考链接。 Spring AOP+AspectJ在XML配置实例在下文中，我们将向你展示如何转换上文中 Spring AOP+AspectJ注解转成基于XML的配置。 对于那些不喜欢注释，使用JDK1.4，则可以基于XML，而不使用 AspectJ。 完整的 XML 实例查看完整的基于XML的 AspectJ 配置文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd "&gt;&lt;aop:aspectj-autoproxy /&gt;&lt;bean id="customerBo" class="com.myprj.customer.bo.impl.CustomerBoImpl" /&gt;&lt;!-- Aspect --&gt;&lt;bean id="logAspect" class="com.myprj.aspect.LoggingAspect" /&gt;&lt;aop:config&gt; &lt;aop:aspect id="aspectLoggging" ref="logAspect"&gt; &lt;!-- @Before --&gt; &lt;aop:pointcut id="pointCutBefore" expression="execution(* com.myprj.customer.bo.CustomerBo.addCustomer(..))" /&gt; &lt;aop:before method="logBefore" pointcut-ref="pointCutBefore" /&gt; &lt;!-- @After --&gt; &lt;aop:pointcut id="pointCutAfter" expression="execution(* com.myprj.customer.bo.CustomerBo.addCustomer(..))" /&gt; &lt;aop:after method="logAfter" pointcut-ref="pointCutAfter" /&gt; &lt;!-- @AfterReturning --&gt; &lt;aop:pointcut id="pointCutAfterReturning" expression="execution(* com.myprj.customer.bo.CustomerBo.addCustomerReturnValue(..))" /&gt; &lt;aop:after-returning method="logAfterReturning" returning="result" pointcut-ref="pointCutAfterReturning" /&gt; &lt;!-- @AfterThrowing --&gt; &lt;aop:pointcut id="pointCutAfterThrowing" expression="execution(* com.myprj.customer.bo.CustomerBo.addCustomerThrowException(..))" /&gt; &lt;aop:after-throwing method="logAfterThrowing" throwing="error" pointcut-ref="pointCutAfterThrowing" /&gt; &lt;!-- @Around --&gt; &lt;aop:pointcut id="pointCutAround" expression="execution(* com.myprj.customer.bo.CustomerBo.addCustomerAround(..))" /&gt; &lt;aop:around method="logAround" pointcut-ref="pointCutAround" /&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;&lt;/beans&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Web工程中的web.xml配置文件]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FJava%20Web%E5%B7%A5%E7%A8%8B%E4%B8%AD%E7%9A%84web.xml%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言1. xml文件xml文件：Extentsible Markup Language即可扩展标记语言，是用来定义其它语言的一种元语言，其前身是SGML(标准通用标记语言)。xml文件是互联网数据传输的重要工具，因为不受编程语言和操作系统的限制，所以可以跨越互联网的任何平台，非常适合Web传输。XML提供统一的方法来描述和交换独立于应用程序或供应商的结构化数据。我们都知道xml文件的一些规则： xml声明一般是xml文档的第一行：\&lt;?xml version=”1.0” encoding=”UTF-8”?>； xml必须有且只有一个根节点，对大小写敏感，标签成对出现，标签不嵌套，但内部元素需要正确嵌套； 属性值用双引号包裹；一个元素可以有多个属性，它的基本格式为：&lt;元素名 属性名=“属性值” 属性名=“属性值”&gt;; 有效的（valid）xml文档：首先xml文档是个格式正规的xml文档，然后又需要满足DTD的要求，这样的xml文档称为有效的xml文档。 2. web应用的组成部分1234567891011121314151617181920graph TB Web应用目录,eclipse-WebContent,idea-webapp --&gt; WEB-IN subgraph Web应用目录,eclipse-WebContent,idea-webapp --&gt; HTML/JSP/CSS/JS end subgraph WEB-IN--&gt;web.xml end subgraph WEB-IN--&gt;classes end subgraph WEB-IN--&gt;lib end subgraph classes--&gt; .Class文件/.xml/.properties配置文件 end subgraph web.xml--&gt; web应用的配置文件 end 3. web.xml文件的作用web.xml文件是整个web应用中最重要的配置文件，它必须放在WEB-INF目录中。在web应用开发中，涉及到web资源的配置都是在web.xml中进行的。例如： 将某个web资源设置为网站首页； 将servlet程序映射到某个url地址上； 为web应用配置监听器； 为web应用配置过滤器； 配置web应用上下文参数、配置Session的参数； 配置spring、springMVC等框架。 一. web.xml标签详解1. xml文档有效检查123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app id="WebApp_ID" version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt; 这是一般在写XML时所做的声明,定义了XML的版本,编码格式,还有重要的指明schema的来源,为http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd；schema是由Sum Microsystems公司(已被Oracle收购)定制的，Schema文件定义了web.xml所对应的xml中有多少种标签元素。 2. 指定欢迎页面或网站首页1234&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index1.jsp&lt;/welcome-file&gt;&lt;/welcome-file-list&gt; 上述例子指定两个欢迎页，从上到下的优先级顺序；若没有上述配置将默认找index.html作为欢迎页；若所有页面都不存在，将会提示The requested resource (/XXX) is not available。 3. 指定错误处理页面 通过错误码指定错误处理页面 1234&lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/error404.jsp&lt;/location&gt;&lt;/error-page&gt; 通过异常类型指定错误处理页面 12345678&lt;error-page&gt; &lt;exception-type&gt;java.lang.Exception&lt;exception-type&gt; &lt;location&gt;/exception.jsp&lt;location&gt;&lt;/error-page&gt;&lt;error-page&gt; &lt;exception-type&gt;java.lang.NullException&lt;/exception-type&gt; &lt;location&gt;/error.jsp&lt;/location&gt; &lt;/error-page&gt; 4. &lt;context-param&gt;&lt;/context-param&gt;设定上下文初始化参数： 1234&lt;context-param&gt;&lt;param-name&gt;param_name&lt;/param-name&gt;&lt;param-value&gt;param_value&lt;/param-value&gt;&lt;/context-param&gt; 此所设定的参数,在JSP网页中可以使用下列方法来取得:${initParam.param_name}；若在Servlet可以使用下列方法来获得:String param_name=getServletContext().getInitParamter(“param_name”)。 5. &lt;session-config&gt;&lt;/session-config&gt;1234&lt;!-- Set timeout to 120 minutes --&gt; &lt;session-config&gt; &lt;session-timeout&gt;120&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;session-config&gt; 用于设置容器的session参数，比如：&lt;session-timeout&gt; 用于指定http session的失效时间。默认时间设置在&lt;jakarta&gt;/conf/web.xml (30 minutes)。&lt;session-timeout&gt;用来指定默认的会话超时时间间隔，以分钟为单位。该元素值必须为整数。如果 session-timeout元素的值为零或负数，则表示会话将永远不会超时。 6. 设置过滤器如下述设置一个编码过滤器，过滤所有资源： 12345678910111213&lt;filter&gt; &lt;description&gt;char encoding filter&lt;/description&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; Filter可认为是Servlet的“增强版”，主要用于对用户请求request进行预处理，也可以对Response进行后处理，是个典型的处理链；因此Filter配置与Servlet的配置非常相似，需要配置两部分：配置Filter名称和Filter拦截器URL模式。区别在于Servlet通常只配置一个URL，而Filter可以同时配置多个请求的URL。 Filter的常用应用场合有：编码器Filter、认证Filter、图片转换Filter、数据压缩Filter、密码Filter、日志和审核Filter等。Filter必须实现javax.servlet.Filter接口，在该接口中定义了三个方法：void init(FilterConfig config)、void destroy()、void doFilter(ServletRequest request,ServletResponse response,FilterChain chain)。 7. 设置监听器配置Listener只要向Web应用注册Listener实现类即可，无需配置参数之类的东西，因为Listener获取的是Web应用ServletContext（application）的配置参数。为Web应用配置Listener的两种方式：1.使用@WebListener修饰Listener实现类即可，2. 在web.xml文档中使用进行配置： 123&lt;listener&gt; &lt;listener-class&gt;监听器类的完整路径&lt;/listener-class&gt; &lt;/listener&gt; 8. Servlet命名与定制URLServlet是个特殊的java类，继承于HttpServlet。客户端通常只有GET和POST两种请求方式，Servlet为了响应则两种请求，必须重写doGet()和doPost()方法。大部分时候，Servlet对于所有的请求响应都是完全一样的，此时只需要重写service()方法即可响应客户端的所有请求。 如下述Spring DispatcherServlet在web.xml中的配置： 12345678910&lt;!-- Spring view分发器 对所有的请求都由business对应的类来控制转发 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;business&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;publishContext&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; 标签存在如下元素标签： &lt;description&gt;：为Servlet指定一个文本描述。 &lt;display-name&gt;：为Servlet提供一个简短的名字被某些工具显示。 &lt;icon&gt;：为Servlet指定一个图标，在图形管理工具中表示该Servlet。 &lt;servlet-name&gt;用来定义servlet的名称，该名称在整个应用中必须是惟一的。 &lt;servlet-class&gt;用来指定servlet的完全限定的名称。 &lt;jsp-file&gt;用来指定应用中JSP文件的完整路径。这个完整路径必须由/开始。 &lt;load-on-startup&gt;：如果load-on-startup元素存在，而且也指定了jsp-file元素，则JSP文件会被重新编译成Servlet，同时产生的Servlet也被载入内存。的内容可以为空，或者是一个整数。这个值表示由Web容器载入内存的顺序。 &lt;servlet-mapping&gt; &lt;servlet-name&gt;：Servlet的名字，唯一性和一致性，与元素中声明的名字一致。 &lt;url-pattern&gt;：指定相对于Servlet的URL的路径。该路径相对于web应用程序上下文的根路径。&lt;servlet-mapping&gt;将URL模式映射到某个Servlet，即该Servlet处理的URL。 二. Spring的web.xml配置集成Web环境的通用配置（加载Spring容器） 12345678&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- 启用spring容器环境上下文监听 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 三. SpringMVC的web.xml配置SpringMVC中的DispatcherServlet是前置控制器，配置在web.xml文件中的。拦截匹配的请求，Servlet拦截匹配规则要自已定义，把拦截下来的请求，依据某某规则分发到目标Controller(我们写的Action)来处理。 12345678910111213&lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:servlet-context.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 四. web.xml的加载顺序web.xml 的加载顺序是：ServletContext -&gt; context-param -&gt; listener -&gt; filter -&gt; servlet ，而同个类型之间的实际程序调用的时候的顺序是根据对应的 mapping 的顺序进行调用的。 附件（完整版SpringMVC的web.xml配置）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt; &lt;!-- 设置编码过滤器，utf-8--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 项目中使用Spring 时，applicationContext.xml配置文件中并没有BeanFactory，要想在业务层中的class 文件中直接引用Spring容器管理的bean可通过以下方式--&gt; &lt;!--1、在web.xml配置监听器ContextLoaderListener--&gt; &lt;!--ContextLoaderListener的作用就是启动Web容器时，自动装配ApplicationContext的配置信息。因为它实现了ServletContextListener这个接口，在web.xml配置这个监听器，启动容器时，就会默认执行它实现的方法 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--2、部署applicationContext的xml文件--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--如果你的DispatcherServlet拦截&quot;/&quot;，为了实现REST风格，拦截了所有的请求，那么同时对*.js,*.jpg等静态文件的访问也就被拦截了。要写在DispatcherServlet的前面， 让 defaultServlet先拦截请求--&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.css&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.swf&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.gif&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.png&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.js&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.xml&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.json&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.map&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/dispatcher-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;!--是启动顺序，让这个Servlet随Servletp容器一起启动。--&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;!--会拦截URL中带“/”的请求。--&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt;&lt;!--指定欢迎页面--&gt; &lt;welcome-file&gt;login.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;error-page&gt; &lt;!--当系统出现404错误，跳转到页面nopage.html--&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/nopage.html&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;!--当系统出现java.lang.NullPointerException，跳转到页面error.html--&gt; &lt;exception-type&gt;java.lang.NullPointerException&lt;/exception-type&gt; &lt;location&gt;/error.html&lt;/location&gt; &lt;/error-page&gt; &lt;session-config&gt;&lt;!--会话超时配置，单位分钟--&gt; &lt;session-timeout&gt;360&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;/web-app&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOP面向切面编程]]></title>
    <url>%2F2015%2F10%2F28%2Fmd_Spring%E6%80%BB%E7%BB%93%2FAOP%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Spring AOP(面向切面编程)框架，用于在模块化方面的横切关注点。简单得说，它只是一个拦截器拦截一些过程，例如，当一个方法执行，Spring AOP 可以劫持一个执行的方法，在方法执行之前或之后添加额外的功能。 在Spring AOP中，有 4 种类型通知(advices)的支持： 通知(Advice)之前 - 该方法执行前运行 通知(Advice)返回之后 – 运行后，该方法返回一个结果 通知(Advice)抛出之后 – 运行方法抛出异常后， 环绕通知 – 环绕方法执行运行，结合以上这三个通知。 一、Spring AOP 通知——Advice1. 前置通知它会在方法执行之前执行。创建一个实现 MethodBeforeAdvice 接口的类。 12345678910111213package com.myprj.aop;import java.lang.reflect.Method;import org.springframework.aop.MethodBeforeAdvice;public class HijackBeforeMethod implements MethodBeforeAdvice&#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println("HijackBeforeMethod : Before method hijacked!"); &#125;&#125; 在 bean 配置文件(applicationContext.xml)，声明 前置通知HijackBeforeMethod 类，创建一个CustomerService的代理类并命名为“customerServiceProxy” 作为一个新的代理对象。 ‘target’ – 定义你想拦截的bean。 ‘interceptorNames’ – 定义要应用这个代理/目标对象的类(通知)。 123456789101112131415161718192021222324&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="myprj Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackBeforeMethodBean" class="com.myprj.aop.HijackBeforeMethod" /&gt; &lt;bean id="customerServiceProxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target" ref="customerService" /&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;hijackBeforeMethodBean&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 2.返回后通知该方法将在返回一个结果之后执行。创建一个实现AfterReturningAdvice接口的类。 12345678910111213package com.myprj.aop;import java.lang.reflect.Method;import org.springframework.aop.AfterReturningAdvice;public class HijackAfterMethod implements AfterReturningAdvice&#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println("HijackAfterMethod : After method hijacked!"); &#125;&#125; bean配置文件 123456789101112131415161718192021222324&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="Yong Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackAfterMethodBean" class="com.myprj.aop.HijackAfterMethod" /&gt; &lt;bean id="customerServiceProxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target" ref="customerService" /&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;hijackAfterMethodBean&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 3.抛出后通知它将在方法抛出一个异常后执行。创建一个实现ThrowsAdvice接口的类，并创建一个afterThrowing方法拦截抛出：IllegalArgumentException异常。 123456789package com.myprj.aop;import org.springframework.aop.ThrowsAdvice;public class HijackThrowException implements ThrowsAdvice &#123; public void afterThrowing(IllegalArgumentException e) throws Throwable &#123; System.out.println("HijackThrowException : Throw exception hijacked!"); &#125;&#125; bean配置文件 123456789101112131415161718192021222324&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="Yong Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackThrowExceptionBean" class="com.myprj.aop.HijackThrowException" /&gt; &lt;bean id="customerServiceProxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target" ref="customerService" /&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;hijackThrowExceptionBean&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 4.环绕通知它结合了上面的三个通知，在方法执行过程中执行。创建一个实现了MethodInterceptor接口的类。必须调用“methodInvocation.proceed();” 继续在原来的方法执行，否则原来的方法将不会执行。 1234567891011121314151617181920212223242526272829303132333435package com.myprj.aop;import java.util.Arrays;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;public class HijackAroundMethod implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; System.out.println("Method name : " + methodInvocation.getMethod().getName()); System.out.println("Method arguments : " + Arrays.toString(methodInvocation.getArguments())); // same with MethodBeforeAdvice System.out.println("HijackAroundMethod : Before method hijacked!"); try &#123; // proceed to original method call Object result = methodInvocation.proceed(); // same with AfterReturningAdvice System.out.println("HijackAroundMethod : Before after hijacked!"); return result; &#125; catch (IllegalArgumentException e) &#123; // same with ThrowsAdvice System.out.println("HijackAroundMethod : Throw exception hijacked!"); throw e; &#125; &#125;&#125; bean配置文件 123456789101112131415161718192021222324&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="Yong Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackAroundMethodBean" class="com.myprj.aop.HijackAroundMethod" /&gt; &lt;bean id="customerServiceProxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target" ref="customerService" /&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;hijackAroundMethodBean&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 二、Spring AOP(Pointcut,Advisor)在上一个Spring AOP通知的例子，一个类的整个方法被自动拦截。但在大多数情况下，可能只需要一种方式来拦截一个或两个方法，这就是为什么引入’切入点’的原因。它允许你通过它的方法名来拦截方法。另外，一个“切入点”必须具有“Advisor’ 相关联。 在Spring AOP中，有三个非常专业术语- Advices, Cut , Advisor，把它在非官方的方式… Advice – 指示之前或方法执行后采取的行动。 Cut – 指明哪些方法应该拦截，通过方法的名称或正则表达式模式。 Advisor – 分组”通知”和”切入点“成为一个单元，并把它传递到代理工厂对象。 切入点的例子可以通过以下两种方式相匹配的方法： 名称匹配 正则表达式匹配 1. 切入点 - 名称匹配的例子通过“切入点”和“advisor”拦截printName()方法。创建NameMatchMethodmyprjcut切入点bean，并提出要在“mappedName”属性值来拦截方法名。 1234&lt;bean id="customermyprjcut" class="org.springframework.aop.support.NameMatchMethodmyprjcut"&gt; &lt;property name="mappedName" value="printName" /&gt; &lt;/bean&gt; 创建 DefaultmyprjcutAdvisor 通知 bean，通知和切入点相关联。 12345&lt;bean id="customerAdvisor" class="org.springframework.aop.support.DefaultmyprjcutAdvisor"&gt; &lt;property name="pointcut" ref="customermyprjcut" /&gt; &lt;property name="advice" ref="hijackAroundMethodBeanAdvice" /&gt; &lt;/bean&gt; 更换代理“interceptorNames”到“customerAdvisor”（它是“hijackAroundMethodBeanAdvice”）。 1234567891011&lt;bean id="customerServiceProxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target" ref="customerService" /&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;customerAdvisor&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 2. 切入点 - 正则表达式的例子也可以通过使用正则表达式匹配切入点方法的名称 – RegexpMethodmyprjcutAdvisor. 12345678910&lt;bean id="customerAdvisor" class="org.springframework.aop.support.RegexpMethodmyprjcutAdvisor"&gt; &lt;property name="patterns"&gt; &lt;list&gt; &lt;value&gt;.*URL.*&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="advice" ref="hijackAroundMethodBeanAdvice" /&gt; &lt;/bean&gt; 现在，它拦截方法名称中有“URL”的方法。在实践中，可以用它来管理DAO层，声明“.DAO.” 拦截所有的DAO类来支持事务。 三、Spring自动代理创建者实例1. BeanNameAutoProxyCreator示例在自动代理机制，只需要创建一个的 BeanNameAutoProxyCreator，并包含所有你的bean(通过bean的名字，或正则表达式名)和“advisor” 作为一个单位。 1234567891011121314151617181920212223242526272829303132333435&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="myprj Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackAroundMethodBeanAdvice" class="com.myprj.aop.HijackAroundMethod" /&gt; &lt;bean id="customerAdvisor" class="org.springframework.aop.support.NameMatchMethodmyprjcutAdvisor"&gt; &lt;property name="mappedName" value="printName" /&gt; &lt;property name="advice" ref="hijackAroundMethodBeanAdvice" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator"&gt; &lt;property name="beanNames"&gt; &lt;list&gt; &lt;value&gt;*Service&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="interceptorNames"&gt; &lt;list&gt; &lt;value&gt;customerAdvisor&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;XML 现在，可以通过“CustomerService”的原始名称获取bean, 如果知道这个bean已经代理。 1CustomerService cust = (CustomerService)appContext.getBean("customerService"); 2. DefaultAdvisorAutoProxyCreator示例这个 DefaultAdvisorAutoProxyCreator 是非常强大的，如果有 bean 相关连，Spring会自动创建一个代理。 123456789101112131415161718192021&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd"&gt; &lt;bean id="customerService" class="com.myprj.customer.services.CustomerService"&gt; &lt;property name="name" value="myprj Mook Kim" /&gt; &lt;property name="url" value="http://www.myprj.com" /&gt; &lt;/bean&gt; &lt;bean id="hijackAroundMethodBeanAdvice" class="com.myprj.aop.HijackAroundMethod" /&gt; &lt;bean id="customerAdvisor" class="org.springframework.aop.support.NameMatchMethodmyprjcutAdvisor"&gt; &lt;property name="mappedName" value="printName" /&gt; &lt;property name="advice" ref="hijackAroundMethodBeanAdvice" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator" /&gt;&lt;/beans&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面试练习与总结第二回（SpringMVC）]]></title>
    <url>%2F2015%2F10%2F23%2Fmd_Java%E9%9D%A2%E8%AF%95%E7%BB%83%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93%2FJava%E9%9D%A2%E8%AF%95%E7%BB%83%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93%E7%AC%AC%E4%BA%8C%E5%9B%9E%EF%BC%88SpringMVC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[临近Java面试的练习与总结，范围可由JavaSE到数据库、Web前端再到JavaEE初级、各类框架、Linux系统等方面，包含知识点和疑难问题点，系列连载发文，可供求职者参阅。 1. MVC思想1.1 什么是MVC？​ MVC（Model View Controller）,是模型（model）—视图（view）—控制器（controller）的缩写，是一种设计模式，也是一种解决问题的方法和思路， 它用一种将业务逻辑、数据、页面显示分离的方法组织代码，使得业务逻辑集聚到一个部件里面，在改进数据结构和个性化定制界面及用户交互的同时，不需要重写编写业务逻辑。 1.2 为什么使用MVC？使用MVC的目的是将Model和View的实现代码分离，从而使同一个程序可以使用不同的表现形式；指导开发者将数据与表现解耦，提高代码、特别是模型部分代码的复用性。 1.3 MVC的结构Ⅰ. 视图视图是用户看到并与之交互的界面（它可以包括一些可以显示数据信息的页面，或者展示形式。例如jsp，html，asp，php）。 Ⅱ. 模型模型表示企业数据和业务规则（可以说就是后端接口，用于业务处理）。在MVC的三个部件中，模型拥有最多的处理任务。例如它可能用象EJBs和ColdFusion Components这样的构件对象来处理数据库。被模型返回的数据是中立的，就是说模型与数据格式无关，这样一个模型能为多个视图提供数据。由于应用于模型的代码只需写一次就可以被多个视图重用，所以减少了代码的重复性。 Ⅲ. 控制器控制器接受用户的输入并调用模型和视图去完成用户的需求（接受客户发送的请求，根据请求调用所对应的接口，然后模型业务处理后返回的数据，由控制器决定调用那个View展示）。 2. MVC框架 MVC框架，它强制性的使应用程序输入、处理和输出分开。使用MVC应用程序被分成三个核心部件：模型、视图、控制器。它们各自处理自己的任务。由此可知，要使用MVC框架，则一定要遵守该框架的规则，它有它的强制性所在。聪明的读者一看就知道，它所使用的三个核心部件其实都是来自MVC模型。只不过在框架中让他们彼此更加独立了去处理各自的任务而已。 最典型的MVC就是JSP + servlet + javabean的模式。 视图：视图是用户看到并与之交互的界面。视图主要有元素HTML ，Adobe Flash，XHTML，XML/XSL,WML等一些标识语言和Web services。模型：模型表示企业数据和业务规则。控制器：控制器接受用户的输入并调用模型和视图去完成用户的需求，所以当单击Web页面中的超链接和发送HTML表单时，控制器本身不输出任何东西和做任何处理。它只是接收请求并决定调用哪个模型构件去处理请求，然后再确定用哪个视图来显示返回的数据。 3. SpringMVC框架3.1 SpringMVC框架简介 SpringMVC是一种基于Java，实现了Web MVC设计模式，请求驱动类型的轻量级Web框架，即使用了MVC架构模式的思想，将Web层进行职责解耦。基于请求驱动指的就是使用请求-响应模型，框架的目的就是帮助我们简化开发，SpringMVC也是要简化我们日常Web开发。 Spring MVC属于SpringFrameWork的后续产品，已经融合在Spring Web Flow里面。 Spring的MVC框架主要由DispatcherServlet、处理器映射、处理器(控制器)、视图解析器、视图组成。 3.2 SpringMVC原理图 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler，可以根据xml配置、注解进行查找 第三步：处理器映射器HandlerMapping向前端控制器返回Handler 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView，ModelAndView是springmvc框架的一个底层对象，包括Model和View 第八步：前端控制器请求视图解析器去进行视图解析，根据逻辑视图名解析成真正的视图(jsp) 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染，视图渲染将模型数据(在ModelAndView对象中)填充到request域 第十一步：前端控制器向用户响应结果]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java面试练习与总结</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面试练习与总结第一回（spring+方法的重写与重载）]]></title>
    <url>%2F2015%2F10%2F23%2Fmd_Java%E9%9D%A2%E8%AF%95%E7%BB%83%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93%2FJava%E9%9D%A2%E8%AF%95%E7%BB%83%E4%B9%A0%E4%B8%8E%E6%80%BB%E7%BB%93%E7%AC%AC%E4%B8%80%E5%9B%9E%EF%BC%88spring%2B%E6%96%B9%E6%B3%95%E7%9A%84%E9%87%8D%E5%86%99%E4%B8%8E%E9%87%8D%E8%BD%BD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[临近Java面试的练习与总结，范围可由JavaSE到数据库、Web前端再到JavaEE初级、各类框架、Linux系统等方面，包含知识点和疑难问题点，系列连载发文，可供求职者参阅。 1.SpringMVC的常用注解 @RequestMapping：处理请求地址映射的注解，常用在类和方法上，若用在类上表示作为类中方法的父路径； 属性： value：指定请求的实际 url； method：指定请求的method类型（get、post、put、delete）； params：指定Request中必须包含的参数，该请求才生效； header：指定Request的请求体中必须某些header的值，该请求才生效； consumes：指定Request请求提交的内容类型（如：application/Json，text/html）； produces: 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回。 @RequestParam：绑定单个请求参数值，request.getParameter(“xxx”)； 属性： value：参数名称； required：是否必须，默认true，表示请求中必须包含该参数，否则抛出异常； defaultValue：默认值，指定请求中没有该参数时的值，此属性使得required的值改为false； @PathVariable：绑定URI地址上的路径变量； 属性： value：参数值； required：是否必须； @ResponseBody：作用于Controller层的方法之上，可以整个返回结果以某种格式返回，如Json、text； @ModelAttribute：被注释的参数或方法添加到Model中，当注释在方法时，请求处理方法Action会将该方法变成一个非请求处理的方法，但其它Action被调用时会首先调用该方法； @SessionAttributes：注释在类上，可以将指定属性值存到Session作用域中； @CookieValue：获取Cookie中的值； @GetMapping：是一个组合注解，是@RequestMapping(method = RequestMethod.GET)的缩写。该注解将HTTP Get 映射到 特定的处理方法上； @PostMapping：与上同理； @PutMapping：与上同理； @DeleteMapping：与上同理； @JsonFormate：将json、xml转换成Java对象，出自于Jackson； @DateTimeFormat：是spring自带的处理框架，主要用于将时间格式化； @JSONField：来源于fastjson，是阿里巴巴的开源框架，主要进行JSON解析和序列化。2. 简述对Spring IoC的理解IoC:Inversion of Control，即“控制反转”，是一种设计思想，在Java设计开发中，IoC意味着将对象的设计交给容器控制。 为什么有IoC容器？Spring框架至于Java Bean的管理，是典型的工厂设计模式，而创建Bean的Factory就是IoC容器；所以IoC容器的出现为开发者提供了更多的便利和基础服务； 什么是IoC？IoC是一种设计思想，主要是为了完成对象的创建和依赖的管理注入。 IoC技术实现原理？我们都知道IoC既是生成Bean的工厂，而要知道工厂是如何产生对象的，我们需要看具体的IOC容器实现，spring提供了许多IOC容器的实现。比如XmlBeanFactory，ClasspathXmlApplicationContext等。 IoC和DI之间的关系？DI—Dependency Injection，即“依赖注入”，IoC通过DI动态的向某个对象提供它所需要的其他对象。3. 方法的重载与方法的重写 区别 重载 重写 英文名 Overloading Overiding 范围 同一类 不同类（继承关系） 方法名 相同 相同 参数列表 不同 相同 修饰符 无关 大于或等于父类 返回值类型 不同 相同（或小于父类） 面向对象思想 多态 继承 抛出父类没有的异常 可以 不可以]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java面试练习与总结</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web页面分页展示+局部刷新]]></title>
    <url>%2F2015%2F09%2F18%2Fmd_Web%E5%89%8D%E7%AB%AF%2FWeb%E9%A1%B5%E9%9D%A2%E5%88%86%E9%A1%B5%E6%98%BE%E7%A4%BA%2B%E5%B1%80%E9%83%A8%E5%88%B7%E6%96%B0%2F</url>
    <content type="text"><![CDATA[整合handlebars.js+自定义分页按钮jquery设计背景：在日常的Web开发中，我们经常做的一件事就是分页设计；Web页面分页展示可以给用户非常良好的体验，所以做好分页将是程序员的一项基本功。分页的后台设计，使用过MyBatis、Hibernate、JFinal等框架的童鞋都知道，后台分页查询只需要套用模板代码，操作极其简单，如果用原生sql语句编写对于我们来说也是常规操作。分页的前端设计，使用原生jQuery和JSTl+EL语句实现，当点击翻页按钮时刷新整个页面将不需要过多的DOM拼接操作，使用EL语句取值便是；但有些业务场景，翻页并不需要刷新页面，所以点击按钮实现局部请求数据，响应之后就需要大量的DOM拼接代码，这样会更加繁琐。本文介绍使用handlebars.js插件实现模板式页面刷新，并采用自定义分页按钮jQuery插件实现按钮展示。 1. 环境搭建1.1 handlebars.jsHandlebars 是 JavaScript 一个语义模板库，通过对view和data的分离来快速构建Web模板。可通过如下地址下载：http://builds.handlebarsjs.com.s3.amazonaws.com/handlebars-v4.0.12.js。 12&lt;script type="text/javascript" src="/js/assets/jquery-3.1.0.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/js/handlebars/handlebars-v4.0.12.js"&gt;&lt;/script&gt; 需要映入jQuery。 1.2 myPagination自定义一个分页按钮插件（或网上下载），有js代码和css样式代码，实现分页按钮的动态展示和发送数据请求。这里提供本文使用下载： http://pj992190r.bkt.clouddn.com/myPagination.css http://pj992190r.bkt.clouddn.com/myPagination.js 12&lt;link rel="stylesheet" href="/js/pagination/myPagination.css"&gt;&lt;script src="/js/pagination/myPagination.js"&gt;&lt;/script&gt; 2. 代码编写2.1 实现业务目标 分页展示数据列表，点击按钮实现局部刷新。 2.2 HTML代码1234567&lt;h2&gt;Hello Pagination!&lt;/h2&gt;&lt;%--表格--%&gt;&lt;table id="myList"&gt;&lt;/table&gt;&lt;%--分页按钮--%&gt;&lt;div id="pagination" class="pagination"&gt;&lt;/div&gt; 准备table标签和翻页按钮容器div标签。 2.2 handlebars模板代码1234567891011121314&lt;script id="entry-template" type="text/x-handlebars-template"&gt; &lt;tr&gt; &lt;th&gt;序号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;/tr&gt; &#123;&#123;#list list&#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123;id&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;name&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;age&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123;/list&#125;&#125;&lt;/script&gt; 自定义handlebars模板，实现DOM拼接。 2.3 JS代码Ⅰ. handlebars操作（加载模板）1234567891011//自定义handlebars模板，DOM拼接（表格）Handlebars.registerHelper('list', function(items, options) &#123; var out = ""; for(var i=0, l=items.length; i&lt;l; i++) &#123; out = out+options.fn(items[i]); &#125; return out;&#125;);//加载自定义handlebars模板var source = $("#entry-template").html();var template = Handlebars.compile(source); Ⅱ. 加载翻页按钮方法123456789101112131415161718//加载翻页按钮function loadPage(total,pages,curPage) &#123; new Page(&#123; id: 'pagination', pageTotal: pages, //必填,总页数 pageAmount: 5, //每页多少条 dataTotal: total, //总共多少条数据 curPage:curPage, //初始页码,不填默认为1 pageSize: 5, //分页个数,不填默认为5 showPageTotalFlag:true, //是否显示数据统计,不填默认不显示 showSkipInputFlag:true, //是否支持跳转,不填默认不显示 getPage: function (page) &#123; //分页查询 queryDatas(page); &#125; &#125;)&#125; Ⅲ. 分页查询方法1234567891011121314151617181920212223242526272829303132//分页查询function queryDatas(pageNum) &#123; var params=&#123;&#125;; params.pageNum=1;//默认查询第一页 params.pageSize=5;//每页显示5条 //params.xxx = "xxx",这里也可以添加查询条件 if(pageNum==null)&#123; params.pageNum=pageNum; &#125; $.ajax(&#123; type:"post", url: "/myJson.json",//这里本地模拟请求的json数据 data:params, dataType:"json", success:function (data) &#123; var list=data.list;//后台传来的数据列表 var total=data.total;//总记录条数 var pages=data.pages;//总记录页数 var curPage=data.pageNum;//当前页数 if(data.total&gt;0)&#123; //调用上述按钮加载方法 loadPage(total,pages,curPage); // 使用handlebars模板拼接列表dom并输出到页面 var html = template(data); document.getElementById("myList").innerHTML = html; &#125;else&#123; $("#pagination").html("&lt;img style='margin-left: -70px;padding:40px;' " + "src='/img/zanwushuju.png'&gt;");//这里进行未查询到数据的操作 &#125; &#125; &#125;)&#125; Ⅴ. 页面加载完毕执行123$(function () &#123; queryDatas(1);//页面初次加载时默认查询第一页&#125;); 2.4 json数据模拟myJson.json文件，模拟本地响应请求。 12345678910111213141516171819202122232425262728293031323334&#123; "pageNum": 1, "pageSize": 5, "size": 5, "total": 7, "pages": 2, "list":[ &#123; "id": "001", "name": "zhangsan", "age": 19 &#125;, &#123; "id": "002", "name": "lisi", "age": 20 &#125;, &#123; "id": "003", "name": "wangwu", "age": 21 &#125;, &#123; "id": "004", "name": "zhaoliu", "age": 22 &#125;, &#123; "id": "005", "name": "tianqi", "age": 23 &#125; ]&#125; 3. 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;%@ page contentType= "text/html;charset=utf-8"%&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt; &lt;title&gt;Pagination&lt;/title&gt; &lt;link rel="stylesheet" href="/js/pagination/myPagination.css"&gt; &lt;style&gt; table,table tr th, table tr td &#123; border:1px solid #0094ff; &#125; table &#123; width: 200px; min-height: 25px; line-height: 25px; text-align: center; border-collapse: collapse;&#125; &lt;/style&gt; &lt;script type="text/javascript" src="/js/assets/jquery-3.1.0.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/js/handlebars/handlebars-v4.0.12.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;Hello Pagination!&lt;/h2&gt;&lt;%--表格--%&gt;&lt;table id="myList"&gt;&lt;/table&gt;&lt;%--分页按钮--%&gt;&lt;div id="pagination" class="pagination"&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src="/js/pagination/myPagination.js"&gt;&lt;/script&gt;&lt;script id="entry-template" type="text/x-handlebars-template"&gt; &lt;tr&gt; &lt;th&gt;序号&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;/tr&gt; &#123;&#123;#list list&#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123;id&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;name&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;age&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123;/list&#125;&#125;&lt;/script&gt;&lt;script type="text/javascript"&gt; $(function () &#123; queryDatas(1); &#125;); //自定义handlebars模板，拼接DOM（列表） Handlebars.registerHelper('list', function(items, options) &#123; var out = ""; for(var i=0, l=items.length; i&lt;l; i++) &#123; out = out+options.fn(items[i]); &#125; return out; &#125;); //加载自定义handlebars模板 var source = $("#entry-template").html(); var template = Handlebars.compile(source); //加载分页按钮 function loadPage(total,pages,curPage) &#123; new Page(&#123; id: 'pagination', pageTotal: pages, //必填,总页数 pageAmount: 5, //每页多少条 dataTotal: total, //总共多少条数据 curPage:curPage, //初始页码,不填默认为1 pageSize: 5, //分页个数,不填默认为5 showPageTotalFlag:true, //是否显示数据统计,不填默认不显示 showSkipInputFlag:true, //是否支持跳转,不填默认不显示 getPage: function (page) &#123; //分页查询 queryDatas(page); &#125; &#125;) &#125; //分页查询 function queryDatas(pageNum) &#123; var params=&#123;&#125;; params.pageNum=1; params.pageSize=5; if(pageNum==null)&#123; params.pageNum=pageNum; &#125; $.ajax(&#123; type:"post", url: "/myJson.json", data:params, dataType:"json", success:function (data) &#123; var list=data.list; var total=data.total; var pages=data.pages; var curPage=data.pageNum; if(data.total&gt;0)&#123; //调用按钮加载 loadPage(total,pages,curPage); // 使用handlebars模板拼接列表dom并输出到页面 var html = template(data); document.getElementById("myList").innerHTML = html; &#125;else&#123; $("#pagination").html("&lt;img style='margin-left: -70px;padding:40px;' " + "src='/img/zanwushuju.png'&gt;"); &#125; &#125; &#125;) &#125;&lt;/script&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Web前端</category>
      </categories>
      <tags>
        <tag>Web前端</tag>
        <tag>handlebarsJS</tag>
      </tags>
  </entry>
</search>
